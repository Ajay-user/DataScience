{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering\n",
    "* Spectral clustering makes no assumption on the shape of cluster\n",
    "    * It can handle intertwined, spiral etc..\n",
    "\n",
    "#### Construct a matrix representation of the graph\n",
    "* Build a Laplacian matrix of the graph\n",
    "\n",
    "<img src='./notes/spectral-cluster-0..png'>\n",
    "\n",
    "#### Compute Eigen-value and Eigen-vectors of the matrix\n",
    "* Find Eigen values and Eigen vectors of the laplacian matrix \n",
    "\n",
    "<img src='./notes/spectral-cluster-1.png'>\n",
    "\n",
    "#### Map each point to a low dimensional representation based on one or more eigen-vector\n",
    "\n",
    "<img src='./notes/spectral-cluster-2.png'>\n",
    "\n",
    "#### Assign points to cluster based on new representation\n",
    "* Look at the components of eigen vector and determine which nodes belong to which cluster\n",
    "\n",
    "\n",
    "<img src='./notes/spectral-cluster-5.png'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://youtu.be/uxsDKhZHDcc'>Video</a> | <a href='https://youtu.be/zkgm0i77jQ8'>Video</a> | <a href='https://youtu.be/cxTmmasBiC8'>Video</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.feature_extraction import image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of frame [100 x 100]\n",
    "l = 100\n",
    "\n",
    "# Return an array representing the indices of a grid.\n",
    "rows, cols = np.indices((l, l))\n",
    "\n",
    "# where do you want to center the circle in the [100 x 100] frame\n",
    "center = (45, 30)\n",
    "# what is the radius of the circle \n",
    "radius = 15\n",
    "\n",
    "# Draw the circle : \n",
    "circle = (rows - center[0])**2 + (cols - center[1])**2 < radius**2\n",
    "\n",
    "# plot the circle\n",
    "plt.matshow(circle.T)\n",
    "plt.scatter(*center, marker='x', c='r');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./plots/how-to-draw-circle.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Draw some circles\n",
    "\n",
    "What is a voxel ? \n",
    "* Voxel : (in computer-based modelling or graphic simulation) each of an array of elements of volume that constitute a notional three-dimensional space.\n",
    "* In 3D computer graphics, a voxel represents a value on a regular grid in three-dimensional space. As with pixels in a 2D bitmap \n",
    "* Voxels themselves do not typically have their position (i.e. coordinates) explicitly encoded with their values. Instead, rendering systems infer the position of a voxel based upon its position relative to other voxels\n",
    "\n",
    "`wikipedia`\n",
    "\n",
    "*\"Voxel is an image of a three-dimensional space region limited by given sizes, which has its own nodal point coordinates in an accepted coordinate system, its own form, its own state parameter that indicates its belonging to some modeled object, and has properties of modeled region.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = 100\n",
    "x, y = np.indices((l, l))\n",
    "\n",
    "center1 = (28, 24)\n",
    "center2 = (40, 50)\n",
    "center3 = (67, 58)\n",
    "center4 = (24, 70)\n",
    "\n",
    "radius1, radius2, radius3, radius4 = 16, 14, 15, 14\n",
    "\n",
    "circle1 = (x - center1[0]) ** 2 + (y - center1[1]) ** 2 < radius1**2\n",
    "circle2 = (x - center2[0]) ** 2 + (y - center2[1]) ** 2 < radius2**2\n",
    "circle3 = (x - center3[0]) ** 2 + (y - center3[1]) ** 2 < radius3**2\n",
    "circle4 = (x - center4[0]) ** 2 + (y - center4[1]) ** 2 < radius4**2\n",
    "\n",
    "# plot the circles\n",
    "circles = circle1 + circle2 + circle3 + circle4\n",
    "plt.matshow(circles);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./plots/draw-four-circles.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering for image segmentation\n",
    "* In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Normalized graph cuts\n",
    "* In these settings, the Spectral clustering approach solves the problem know as `‘normalized graph cuts’`\n",
    "* The image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.\n",
    "\n",
    "<br>\n",
    "\n",
    "* <div style='color:salmon'>As the algorithm tries to balance the volume (ie balance the region sizes), if we take circles with different sizes, the segmentation fails.</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='color:green'>\n",
    "We use a mask that limits to the foreground: <br>The problem that we are\n",
    "interested in here is not separating the objects from the background,\n",
    "but separating them one from the other.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image with four circles\n",
    "img = circle1 + circle2 + circle3 + circle4\n",
    "\n",
    "# Create a mask for limiting the foreground\n",
    "mask = img.astype(bool)\n",
    "\n",
    "img = img.astype(float)\n",
    "\n",
    "img += 1 + 0.2 * np.random.randn(*img.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].matshow(img)\n",
    "ax[0].set(title='Image')\n",
    "ax[1].matshow(mask)\n",
    "ax[1].set(title='Mask');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./plots/img_and_mask.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the image into a graph | impose connectivity in estimators\n",
    "* Why are we converting the image into a graph ?\n",
    "    * <div style='color:steelblue'>In Spectral Clustering the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</ div>\n",
    "    * <div style='color:steelblue'>For two clusters, SpectralClustering solves a convex relaxation of the normalized cuts problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster.</ div>\n",
    "\n",
    "<br>\n",
    "\n",
    "* Several estimators in the scikit-learn can use connectivity information between features or samples. \n",
    "    * For instance Ward clustering (Hierarchical clustering) can cluster together only neighboring pixels of an image, thus forming contiguous patches:\n",
    "\n",
    "<br>\n",
    "\n",
    "* **For this purpose, the estimators use a `‘connectivity’ matrix`, giving which samples are connected.**\n",
    "\n",
    "* The function `img_to_graph` returns such a matrix from a 2D or 3D image. \n",
    "* The function `grid_to_graph` build a connectivity matrix for images given the shape of these image.\n",
    "\n",
    "<div style='color:green'>These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (Hierarchical clustering), but also to build precomputed kernels, or similarity matrices.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = image.img_to_graph(img, mask=mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color:salmon'>\n",
    "Warning Transforming distance to well-behaved similarities<br>\n",
    "<br>\n",
    "Note that if the values of your similarity matrix are not well distributed, then the spectral problem will be singular and the problem is not solvable. \n",
    "<h4>e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable.</h4> In which case it is advised to apply a transformation to the entries of the matrix.\n",
    "\n",
    "<h5 style='color:seagreen'>similarity = np.exp(-beta * distance / distance.std())</h5>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.data = np.exp(-graph.data / graph.data.std())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SpectralClustering(affinity=&#x27;precomputed&#x27;, eigen_solver=&#x27;arpack&#x27;, n_clusters=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SpectralClustering</label><div class=\"sk-toggleable__content\"><pre>SpectralClustering(affinity=&#x27;precomputed&#x27;, eigen_solver=&#x27;arpack&#x27;, n_clusters=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SpectralClustering(affinity='precomputed', eigen_solver='arpack', n_clusters=4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral = SpectralClustering(n_clusters=4, eigen_solver='arpack', affinity='precomputed')\n",
    "spectral.fit(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img = np.random.randn(*mask.shape)\n",
    "\n",
    "labeled_img[mask] = spectral.labels_\n",
    "labeled_img[~mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(img)\n",
    "ax[0].set(title='Image')\n",
    "ax[1].imshow(labeled_img, cmap=plt.cm.Paired)\n",
    "ax[1].set(title='Clusters');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./plots/img_and_cluster.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dd57416d08487125cddc31714a1d5a29ab9aaf930e8420812b05ce6347e3520"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
