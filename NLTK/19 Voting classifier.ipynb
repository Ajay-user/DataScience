{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb736f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, CategoricalNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from statistics import mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec97e15",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02396ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total documents in our dataset 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['mr', '.', 'bean', ',', 'a', 'bumbling', 'security', ...], 'neg'),\n",
       " (['when', 'casting', 'the', 'key', 'part', 'of', 'the', ...], 'pos'),\n",
       " (['there', 'is', 'a', 'scene', 'in', 'patch', 'adams', ...], 'neg'),\n",
       " (['and', 'i', 'thought', '\"', 'stigmata', '\"', 'would', ...], 'neg'),\n",
       " (['some', 'critics', ',', 'including', 'siskel', '&', ...], 'pos')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a  dataset using movie reviws data\n",
    "documents = []\n",
    "for category in movie_reviews.categories():\n",
    "    for file in movie_reviews.fileids(category):\n",
    "        review = movie_reviews.words(fileids=file)\n",
    "        documents.append((review,category))\n",
    "        \n",
    "# total documents \n",
    "print('total documents in our dataset',len(documents))\n",
    "\n",
    "# let's shuffle the data\n",
    "random.seed(42)\n",
    "random.shuffle(documents)\n",
    "\n",
    "# lets check the first five doc + labels\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b9539",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb4299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS : ['i', 'me', 'my', 'myself', 'we']\n",
      "length of vocab 955610\n"
     ]
    }
   ],
   "source": [
    "vocab = movie_reviews.words()\n",
    "\n",
    "# STOP WORDS\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "print(\"STOP WORDS :\",STOP_WORDS[:5])\n",
    "\n",
    "# improve the vocab\n",
    "vocab = [word for word in vocab if word not in STOP_WORDS]\n",
    "print('length of vocab',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e35e5",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b378185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.66 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "freq = nltk.FreqDist(vocab)\n",
    "# top most common words\n",
    "top_500 = freq.most_common()[:500]\n",
    "top_500 = [tup[0] for tup in top_500]\n",
    "\n",
    "\n",
    "features = []\n",
    "\n",
    "for review, sentiment in documents:\n",
    "    lookup = {word:True for word in review}\n",
    "    mulit_hot_vector = {}\n",
    "    for word in top_500:\n",
    "        try:\n",
    "            if lookup[word]:\n",
    "                mulit_hot_vector[word]=True\n",
    "        except:\n",
    "            mulit_hot_vector[word]=False\n",
    "    \n",
    "    features.append((mulit_hot_vector,sentiment))\n",
    "    \n",
    "\n",
    "# Test driven development\n",
    "assert len(documents) == len(features)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736c0ab",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfffa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = features[:1900]\n",
    "test_set = features[1900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04276e3f",
   "metadata": {},
   "source": [
    "## Training different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a45c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK classifier\n",
    "bayes = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# sklearn bayes classifiers\n",
    "gnb = SklearnClassifier(GaussianNB(),sparse=False).train(train_set)\n",
    "mnb = SklearnClassifier(MultinomialNB()).train(train_set)\n",
    "cnb = SklearnClassifier(ComplementNB()).train(train_set)\n",
    "bnb = SklearnClassifier(BernoulliNB()).train(train_set)\n",
    "catnb = SklearnClassifier(CategoricalNB(), sparse=False).train(train_set)\n",
    "# sklearn linear models\n",
    "lr = SklearnClassifier(LogisticRegression(max_iter=500)).train(train_set)\n",
    "sgd = SklearnClassifier(SGDClassifier()).train(train_set)\n",
    "# Support vectors\n",
    "svc =SklearnClassifier(LinearSVC(max_iter=5000)).train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf5e1c",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6ef2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self, classifiers):\n",
    "        self.classifiers = classifiers\n",
    "        \n",
    "    def classify(self, feature_set):\n",
    "        self.feature_set = feature_set\n",
    "        model_outputs = []\n",
    "        for model in self.classifiers:\n",
    "            outputs = model.classify_many([tup[0] for tup in feature_set])\n",
    "            model_outputs.append(outputs)\n",
    "        return model_outputs\n",
    "    \n",
    "    def vote_and_confidence(self, feature_set):\n",
    "        self.confidence_scores = []\n",
    "        model_outputs = self.classify(feature_set)\n",
    "        \n",
    "        for i, votes in enumerate(zip(*model_outputs)):\n",
    "            majority = mode(votes)\n",
    "            confidence = votes.count(majority) / len(votes)\n",
    "            self.confidence_scores.append((majority, confidence))\n",
    "            \n",
    "        return self.confidence_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d97e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance\n",
    "\n",
    "classifiers = [gnb, mnb, cnb, bnb, catnb, lr, sgd, svc]\n",
    "\n",
    "clf = VotingClassifier(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f96c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting prediction and confidence for test-set reviews\n",
    "predictions = clf.vote_and_confidence(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee1e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the ouput predictions \n",
    "def evaluate(predictions, i):\n",
    "    true_label = test_set[i][1]\n",
    "    predicted_label = predictions[i][0]\n",
    "    confidence = predictions[i][1]\n",
    "    print(f'''\n",
    "    Model prediction for the test-review index:{i} is {predicted_label}\n",
    "    \\nThe true label is {true_label}\\nConfidence:{confidence*100:.1f}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f6ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model prediction for the test-review index:0 is neg\n",
      "    \n",
      "The true label is neg\n",
      "Confidence:100.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluate(predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92c1f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model prediction for the test-review index:10 is neg\n",
      "    \n",
      "The true label is neg\n",
      "Confidence:100.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluate(predictions, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df5dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model prediction for the test-review index:90 is neg\n",
      "    \n",
      "The true label is neg\n",
      "Confidence:100.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluate(predictions, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09280588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
