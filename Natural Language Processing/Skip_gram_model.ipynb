{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHGOGNbPtmXofzh8i3It65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-user/ML-DL-RL-repo/blob/master/Natural%20Language%20Processing/Skip_gram_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##word2vec \n",
        "word2vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets. \n",
        "\n",
        "Embeddings learned through word2vec have proven to be successful on a variety of downstream natural language processing tasks..\n",
        "\n",
        "### Two methods for learning representations of words\n",
        "\n",
        "* `Continuous bag-of-words model`: predicts the middle word based on surrounding context words.\n",
        "  * a bag-of-words model predicts a word given the neighboring context\n",
        "\n",
        "* `Continuous skip-gram model`: predicts words within a certain range before and after the current word in the same sentence.\n",
        "  * a skip-gram model predicts the context (or neighbors) of a given word\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Skip-gram and negative sampling\n",
        "\n",
        "Lets build a model that is trained on skip-grams, which are n-grams that allow tokens to be skipped. \n",
        "\n",
        "The context of a word can be represented through a set of skip-gram pairs of (target_word, context_word) where context_word appears in the neighboring context of target_word.\n",
        "\n",
        "\n",
        "* The context words for a word in a sentence is defined by a window size. \n",
        "\n",
        "* The window size determines the span of words on either side of a target_word that can be considered a context word.\n",
        "\n",
        "* A window size of `n` implies `n` words on each side of target-word , with a total window span of `2*n+1` words across a word.\n",
        "\n",
        "**sample text** <br>\n",
        "`The wide road shimmered in the hot sun.`\n",
        "\n",
        "**target-word = `shimmered`**\n",
        "\n",
        "**window size = 2** <br>\n",
        "`The [wide road shimmered in the] hot sun.`\n",
        "\n",
        "**skip-grams** <br>\n",
        "* `shimmered wide`\n",
        "* `shimmered road`\n",
        "* `shimmered in`\n",
        "* `shimmered the`\n",
        "\n",
        "\n",
        "## Model architecture\n",
        "\n",
        "<img src='https://miro.medium.com/max/720/1*fTjKtIwaRREoXh9Oj7zlyQ.webp'>\n",
        "\n",
        "## Cost function\n",
        "\n",
        "* The training objective of the skip-gram model is to maximize the probability of predicting context words given the target word. \n",
        "\n",
        "**cost function**\n",
        "\n",
        "`log(p(context-word | target-word, theta))`\n",
        "\n",
        "`theta` represent the model parameters that we have to learn\n",
        "\n",
        "we seek model parameters that optimize this cost function\n",
        "\n",
        "**The basic skip-gram formulation defines this probability using the softmax function.**\n",
        "\n",
        "<img src='https://miro.medium.com/max/720/1*DV1xvqFEB12EI776KpEPhA.webp'>\n",
        "\n",
        "## Bottle-neck\n",
        "\n",
        "<img src='https://miro.medium.com/max/720/1*rBtSsuivvRdxUVOXD7Xc_w.webp'>\n",
        "\n",
        "**Computing the denominator of this formulation involves performing a full softmax over the entire vocabulary words, which are often very large**\n",
        "\n",
        "How can we overcome this bottleneck layer?\n",
        "\n",
        "Can we approxiamte the softmax-layer? \n",
        "\n",
        "## Noise Contrastive Estimation (NCE) as loss function\n",
        "The noise contrastive estimation (NCE) loss function is an efficient approximation for a full softmax. \n",
        "\n",
        "With an objective to learn word embeddings instead of modeling the word distribution, the NCE loss can be simplified to use negative sampling.\n",
        "\n",
        "## What is negative sampling?\n",
        "\n",
        "The simplified negative sampling objective for a target word is to distinguish the context word from `num_ns` negative samples drawn from noise distribution `Pn(w)` of words. \n",
        "\n",
        "## An efficient approximation of full softmax over the vocabulary\n",
        "Pose the loss for a target word as a classification problem between the `context word` and `num_ns` negative samples.\n",
        "\n",
        "## An example of a negative-sample\n",
        "Words that does not appear in the context-window of the target word\n",
        "\n",
        "**sample text** <br>\n",
        "`The wide road shimmered in the hot sun.`\n",
        "\n",
        "**target-word = `shimmered`**\n",
        "\n",
        "**window size = 2** <br>\n",
        "`The [wide road shimmered in the] hot sun.`\n",
        "\n",
        "**negative-sample** <br>\n",
        "* `<target-word negative-sample>`\n",
        "* `shimmered The`\n",
        "* `shimmered hot`\n",
        "* `shimmered sun`\n"
      ],
      "metadata": {
        "id": "Y3HvEo5_IOLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vU_xrX56IEHC"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download text corpus ðŸ§²"
      ],
      "metadata": {
        "id": "qcSM6Czma67K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file(fname='shakespeare.txt', origin='https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_file)"
      ],
      "metadata": {
        "id": "fPLypr2IazjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4a42ba-d5ba-4961-8aaa-a8a128de7ec8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets view sentences from the corpus ðŸ‘“"
      ],
      "metadata": {
        "id": "Hc3xCjltbe5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = path_to_file.read_text(encoding='utf-8')\n",
        "lines = raw.splitlines()\n",
        "\n",
        "# print first 25 lines\n",
        "print('\\n'.join(lines[:25]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI0UuKSKbbwY",
        "outputId": "9b247397-b6b2-4201-ec6c-0be6fae2f3d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a dataset ðŸ“˜\n",
        "* Read the data\n",
        "* Split the lines\n",
        "* Filter off new-lines and whitespaces"
      ],
      "metadata": {
        "id": "1ZIamrV9cRUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_ds = tf.data.TextLineDataset(filenames=path_to_file).filter(lambda x: tf.strings.length(x)>0)\n",
        "\n",
        "for line in lines_ds.take(5):\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzNcnWUVbdie",
        "outputId": "d4ac5b33-e214-46f4-8c45-cd334218a45f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Before we proceed any further, hear me speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'All:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Speak, speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize sentences from the corpus ðŸ“–\n",
        "\n",
        "* Convert the sentences to lowercase\n",
        "* Remove punctuation"
      ],
      "metadata": {
        "id": "Qt7m4A1Md-41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardizer(input):\n",
        "  lower = tf.strings.lower(input)\n",
        "  remove_punctuation = tf.strings.regex_replace(input=lower, pattern=f'[{string.punctuation}]', rewrite='')\n",
        "  return remove_punctuation"
      ],
      "metadata": {
        "id": "CgxxHmnOdKtW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "vocab_size = 4096\n",
        "sequence_length = 10"
      ],
      "metadata": {
        "id": "LZqv5IS8fbKV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = tf.keras.layers.TextVectorization(max_tokens=vocab_size, standardize=custom_standardizer,\n",
        "                                               output_mode='int', output_sequence_length=sequence_length)"
      ],
      "metadata": {
        "id": "KNaoKWQxegIM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Call TextVectorization.adapt on the text dataset to create vocabulary."
      ],
      "metadata": {
        "id": "f33s0eyxfwAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(lines_ds.batch(1024))"
      ],
      "metadata": {
        "id": "z9DjEBEBfojr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDMSy50hftTi",
        "outputId": "795f4dfe-7a5c-41d1-80a8-e3968ab0fc77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorized text"
      ],
      "metadata": {
        "id": "85zgB_wxiYz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_ds = lines_ds.batch(1024).prefetch(tf.data.AUTOTUNE).map(vectorizer).unbatch()"
      ],
      "metadata": {
        "id": "S273JvbtgCVp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text = list(vectorized_ds.as_numpy_iterator())\n",
        "\n",
        "for vector in vectorized_text[:5]:\n",
        "  print(vector,'==>',[vectorizer.get_vocabulary()[i] for i in vector ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R53HJOXRiYRa",
        "outputId": "7d52677e-41a7-47f7-d714-293b8eb8703d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 89 270   0   0   0   0   0   0   0   0] ==> ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
            "[138  36 982 144 673 125  16 106   0   0] ==> ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
            "[34  0  0  0  0  0  0  0  0  0] ==> ['all', '', '', '', '', '', '', '', '', '']\n",
            "[106 106   0   0   0   0   0   0   0   0] ==> ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
            "[ 89 270   0   0   0   0   0   0   0   0] ==> ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate skip-grams \n",
        "\n",
        "The `tf.keras.preprocessing.sequence` module provides useful functions that simplify data preparation for word2vec. \n",
        "\n",
        "\n",
        "* use the `tf.keras.preprocessing.sequence.skipgrams`\n",
        "\n",
        "### Skip-gram sampling table\n",
        "A large dataset means larger vocabulary with higher number of more frequent words such as stopwords. \n",
        "\n",
        "Training examples obtained from sampling commonly occurring words don't add much useful information for the model to learn from. \n",
        "\n",
        "It's recommended to subsampling of frequent words as a helpful practice to improve embedding quality.\n",
        "\n",
        "The `tf.keras.preprocessing.sequence.skipgrams` function accepts a sampling table argument to encode probabilities of sampling any token. \n",
        "\n",
        "You can use the `tf.keras.preprocessing.sequence.make_sampling_table` to generate a word-frequency rank based probabilistic sampling table and pass it to the skipgrams function.\n"
      ],
      "metadata": {
        "id": "lZj4uLgfiBZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW = 2"
      ],
      "metadata": {
        "id": "sNc0xNk9jkLo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=vectorizer.vocabulary_size())"
      ],
      "metadata": {
        "id": "ULFJevIJoEQj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate positive skip-grams from one sentence\n",
        "\n",
        "Lets to set the `negative_samples` param to `zero` to generate only postive skip-grams\n"
      ],
      "metadata": {
        "id": "Hnep5ZKUkqiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = vectorized_text[1]\n",
        "print(sentence,'==>',[vectorizer.get_vocabulary()[i] for i in sentence ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYFQUSMiks7f",
        "outputId": "6fa39126-75e5-44bd-a39f-088c6501a4d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[138  36 982 144 673 125  16 106   0   0] ==> ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_skip_grams, label = tf.keras.preprocessing.sequence.skipgrams(sequence=sentence, \n",
        "                                                          vocabulary_size=vectorizer.vocabulary_size(),\n",
        "                                                          window_size=WINDOW, negative_samples=0.0, \n",
        "                                                          sampling_table=sampling_table)"
      ],
      "metadata": {
        "id": "_ehoQ7OOh7ky"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print a few positive skip-grams:"
      ],
      "metadata": {
        "id": "ub9D9yg8l55l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for target_word, context_word in positive_skip_grams:\n",
        "  print(f'{vectorizer.get_vocabulary()[target_word]} [{target_word}] <===> {vectorizer.get_vocabulary()[context_word]} [{context_word}]' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSCVn9vj--G",
        "outputId": "e00a488c-2ed9-460c-88ee-e14dc3ddd128"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speak [106] <===> hear [125]\n",
            "proceed [982] <===> any [144]\n",
            "proceed [982] <===> we [36]\n",
            "proceed [982] <===> further [673]\n",
            "speak [106] <===> me [16]\n",
            "proceed [982] <===> before [138]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative sampling for non-context words\n",
        "\n",
        "The skipgrams function returns all positive skip-gram pairs by sliding over a given window span. \n",
        "\n",
        "**To produce additional skip-gram pairs that would serve as negative samples for training, you need to sample random words from the vocabulary.**\n",
        "\n",
        "\n",
        "* Use the `tf.random.log_uniform_candidate_sampler` function to sample `num_ns` number of negative samples for a given target word in a window. \n",
        "\n",
        "* **Key Point**: `num_ns` in the `[5, 20]` range is shown to work best for smaller datasets, while num_ns in the `[2, 5]` range suffices for larger datasets."
      ],
      "metadata": {
        "id": "dnxuzAb9pGqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get target and context words for one positive skip-gram.\n",
        "target_word, context_word = positive_skip_grams[0]\n",
        "\n",
        "# Set the number of negative samples per positive context.\n",
        "num_ns = 4"
      ],
      "metadata": {
        "id": "T5i74biqoq0h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TARGET WORD  :',target_word)\n",
        "print('CONTEXT WORD :',context_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am0sg9zDqkbh",
        "outputId": "f99fbda7-3d68-4029-cf72-c28f38fb39a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET WORD  : 106\n",
            "CONTEXT WORD : 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.random.log_uniform_candidate_sampler`\n",
        "\n",
        "* `true_classes`\tA Tensor of type int64 and shape `[batch_size,num_true]`. The target classes.\n",
        "* `num_true`\tAn int. The number of target classes per training example.\n",
        "* `num_sampled`\tAn int. The number of classes to randomly sample.\n",
        "* `unique`\tA bool. Determines whether all sampled classes in a batch are unique.\n",
        "* `range_max`\tAn int. The number of possible classes.\n",
        "* `seed`\tAn int. An operation-specific seed. Default is 0.\n",
        "* `name`\tA name for the operation (optional)."
      ],
      "metadata": {
        "id": "SZb4Lt36rDMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_class = tf.constant(context_word, dtype=tf.int64)\n",
        "context_class = tf.reshape(context_class, shape=[1,1])\n",
        "\n",
        "context_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tl6SeSGrghI",
        "outputId": "aebfe4f5-7ffc-4a44-88fb-860f7d53b9d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[125]])>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_candidates,_,_=   tf.random.log_uniform_candidate_sampler(true_classes=context_class, num_true=1, \n",
        "                                                               num_sampled=num_ns,\n",
        "                                                               unique=True, \n",
        "                                                               range_max=vectorizer.vocabulary_size())"
      ],
      "metadata": {
        "id": "z3WNRe2zqr-w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24RW08VtAtm",
        "outputId": "b3008a3d-de1c-47c6-dbf2-fe14d7e03dd5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([126,  25, 771,  80])>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[vectorizer.get_vocabulary()[i] for i in sampled_candidates] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odExLk8mtC-N",
        "outputId": "c00b7354-4fa9-4b55-8542-9dd44a74d2db"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['life', 'as', 'somerset', 'make']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct one training example\n",
        "\n",
        "For a given positive (target_word, context_word) skip-gram, you now also have `num_ns` negative sampled context words that do not appear in the window size neighborhood of target_word. \n",
        "\n",
        "one training example = `(target_word, [context_word, negative_samples], [labels])`"
      ],
      "metadata": {
        "id": "4LHRmCUFtfe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_and_negatives = [context_word, *sampled_candidates.numpy()]\n",
        "labels = [1] + [0]*num_ns"
      ],
      "metadata": {
        "id": "sK3GvP8vtQPt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_example = (target_word, context_and_negatives, labels)\n",
        "training_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4vDweePvA6M",
        "outputId": "a0c105c2-ed00-4e65-e592-54e9bdd899bb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, [125, 126, 25, 771, 80], [1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skip-grams generator"
      ],
      "metadata": {
        "id": "BuNuOPIuwNHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def skip_grams_generator(inputs, vocab_size, num_ns, window_size, seed):\n",
        "  target_words, context_and_negatives, labels = [],[],[]\n",
        "  # SAMPLING TABLE\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=vocab_size)\n",
        "  for sentence_vector in inputs:\n",
        "    # POSITIVE SKIP GRAMS\n",
        "    positive_skip_grams,_ = tf.keras.preprocessing.sequence.skipgrams(sequence=sentence_vector,\n",
        "                                                                    vocabulary_size=vocab_size,\n",
        "                                                                    window_size=window_size,\n",
        "                                                                    negative_samples=0.0,\n",
        "                                                                    sampling_table=sampling_table)\n",
        "    # NEGATIVE SAMPLING\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.constant(context_word, dtype=tf.int64)\n",
        "      context_class = tf.reshape(context_class, shape=[1,1])\n",
        "      negative_samples,_,_=   tf.random.log_uniform_candidate_sampler(true_classes=context_class, num_true=1, \n",
        "                                                               num_sampled=num_ns,\n",
        "                                                               unique=True, \n",
        "                                                               range_max=vocab_size,\n",
        "                                                               seed=seed)\n",
        "\n",
        "    \n",
        "      # TARGET WORDS\n",
        "      target_words.append(target_word)\n",
        "      # CONTEXT AND NEGATIVES\n",
        "      concated = tf.concat([tf.squeeze(context_class, axis=1) ,negative_samples], axis=0)\n",
        "      context_and_negatives.append(concated)\n",
        "      # LABELS\n",
        "      label = tf.constant([1]+[0]*num_ns, dtype=tf.int64)\n",
        "      labels.append(label)\n",
        "\n",
        "  \n",
        "  return np.array(target_words), np.array(context_and_negatives), np.array(labels)\n",
        "    "
      ],
      "metadata": {
        "id": "12OaFbpAvOHK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_words, context_and_negatives, labels = skip_grams_generator(vectorized_text,\n",
        "                                                                   vocab_size=vectorizer.vocabulary_size(),\n",
        "                                                                   num_ns=4,\n",
        "                                                                   window_size=2,\n",
        "                                                                   seed=42)"
      ],
      "metadata": {
        "id": "vNpvGety2gLe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TARGET WORDS SHAPE : ',target_words.shape)\n",
        "print('CONTEXT AND NEGATIVE SAMPLES SHAPE : ',context_and_negatives.shape)\n",
        "print('LABELS SHAPE : ',labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZU8S2eOM4VE",
        "outputId": "5786d44f-8cc1-4d87-d6ec-c0bda8792aa4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET WORDS SHAPE :  (65436,)\n",
            "CONTEXT AND NEGATIVE SAMPLES SHAPE :  (65436, 5)\n",
            "LABELS SHAPE :  (65436, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('TARGET WORDS example : ',target_words[0])\n",
        "print('CONTEXT AND NEGATIVE SAMPLES example : ',context_and_negatives[0])\n",
        "print('LABELS example : ',labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIqSGnCJUCpy",
        "outputId": "2e99783c-9a7a-476a-9544-3742b6f3ebe3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET WORDS example :  1286\n",
            "CONTEXT AND NEGATIVE SAMPLES example :  [344 170  19 826  57]\n",
            "LABELS example :  [1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a training example"
      ],
      "metadata": {
        "id": "BK9i9_WnOEIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(((target_words, context_and_negatives), labels))\n",
        "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "-ckbM1RaOCz0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure for performance\n",
        "* Apply Dataset.cache and Dataset.prefetch to improve performance:"
      ],
      "metadata": {
        "id": "pahUUuGTN_h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "piAQWuke0Xiu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets looks at a training sample\n",
        "train_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "example_target_batch, example_context_batch = train_batch\n",
        "example_target = example_target_batch[0]\n",
        "example_context = example_context_batch[0]\n",
        "example_label = label_batch[0]\n",
        "\n",
        "print('TARGET WORD example : ',example_target)\n",
        "print('CONTEXT AND NEGATIVE SAMPLEs example : ',example_context)\n",
        "print('LABELS example : ',example_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xRnAe-ASeT6",
        "outputId": "18fd80fa-ecbb-4b76-a671-cafbe2c36a0b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TARGET WORD example :  tf.Tensor(3370, shape=(), dtype=int64)\n",
            "CONTEXT AND NEGATIVE SAMPLEs example :  tf.Tensor([   3 1414  239    0 1046], shape=(5,), dtype=int64)\n",
            "LABELS example :  tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling \n",
        "\n",
        "The word2vec model can be implemented as a classifier to identify the true context words from skip-grams.\n",
        "\n",
        "* a training example = `(target_word, [context_word, negative_samples], [labels])`\n",
        "\n",
        "The false context words are obtained through negative sampling. \n",
        "\n",
        "We can perform a dot product multiplication between the embeddings of target and context words to obtain predictions for labels and compute the loss function against true labels in the dataset.\n",
        "\n",
        "\n",
        "####  Use the Keras Subclassing API to define your word2vec model with the following layers:\n",
        "\n",
        "* `target_embedding`: A `tf.keras.layers.Embedding layer`, which looks up the embedding of a word \n",
        "\n",
        "* `context_embedding`: Another `tf.keras.layers.Embedding layer`, which looks up the embedding of a word\n",
        "\n",
        "* Create a layer that computes the dot product of target and context embeddings from a training pair.\n",
        "\n",
        "* `flatten`: A `tf.keras.layers.Flatten` layer to flatten the results of dots layer into logits.\n",
        "\n",
        "With the subclassed model, you can define the call() function that accepts `(target, context)` pairs which can then be passed into their corresponding embedding layer. \n",
        "\n",
        "Reshape the context_embedding to perform a dot product with target_embedding and return the flattened result.\n",
        "\n"
      ],
      "metadata": {
        "id": "vNsURKPlPnWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGramModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(SkipGramModel, self).__init__()\n",
        "    self.target_embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='target_embedding')\n",
        "    self.context_embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='context_embedding')\n",
        "\n",
        "  # FORWARD PASS\n",
        "  def call(self, inputs):\n",
        "    target, context = inputs\n",
        "\n",
        "    # [batch, ] --> [batch, embed_dims]\n",
        "    target_embedding = self.target_embed(target)\n",
        "    # [batch, seq] --> [batch, seq, embed_dims]\n",
        "    context_embedding = self.context_embed(context)\n",
        "\n",
        "    # use dot-product to find similarity score\n",
        "    dots = tf.einsum('be,bse->bs', target_embedding, context_embedding)\n",
        "\n",
        "    return dots\n",
        "\n"
      ],
      "metadata": {
        "id": "3f3ICQhxN2wF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIMS = 128\n",
        "model = SkipGramModel(vocab_size=vectorizer.vocabulary_size(), embedding_dim=EMBED_DIMS)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "AFcQhRLPN2tM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_tWCKARN2qd",
        "outputId": "072e3d01-f514-40ea-dbe0-3d0c6f8e26fa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 20ms/step - loss: 1.6083 - accuracy: 0.2326\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.5890 - accuracy: 0.5559\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.5411 - accuracy: 0.6063\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 1.4576 - accuracy: 0.5775\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.3587 - accuracy: 0.5806\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.2616 - accuracy: 0.6074\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.1713 - accuracy: 0.6408\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.0877 - accuracy: 0.6757\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 1.0102 - accuracy: 0.7092\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.9381 - accuracy: 0.7382\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.8712 - accuracy: 0.7647\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.8093 - accuracy: 0.7861\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.7521 - accuracy: 0.8059\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.6997 - accuracy: 0.8236\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.6516 - accuracy: 0.8382\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.6076 - accuracy: 0.8525\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5676 - accuracy: 0.8647\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.5311 - accuracy: 0.8760\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4979 - accuracy: 0.8862\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.4676 - accuracy: 0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss']);\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs');"
      ],
      "metadata": {
        "id": "sOUc2mEqfbsp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a9b5b3bb-9e25-449b-bc43-36b7c8c51680"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy']);\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kvXhz5x7mkez",
        "outputId": "262ea71d-f8f6-47bd-e4a5-4e58cdb97539"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkgGMHpUmkcO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6OY-RwFmBsv"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}