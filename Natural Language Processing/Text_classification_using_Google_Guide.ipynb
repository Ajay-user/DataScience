{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text classification using Google Guide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNx75JOnHUkCxZ6iBS1g4Zy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-user/DataScience/blob/master/Natural%20Language%20Processing/Text_classification_using_Google_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOmzr3SVYsVr"
      },
      "source": [
        "google guide : https://developers.google.com/machine-learning/guides/text-classification\n",
        "\n",
        "this guide use the Internet Movie Database (IMDb) movie reviews dataset to illustrate the workflow. This dataset contains movie reviews posted by people on the IMDb website, as well as the corresponding labels (“positive” or “negative”) indicating whether the reviewer liked the movie or not. This is a classic example of a sentiment analysis problem.\n",
        "\n",
        "## Text Classification Workflow\n",
        "Here’s a high-level overview of the workflow used to solve machine learning problems:\n",
        "\n",
        "* Step 1: Gather Data\n",
        "* Step 2: Explore Your Data\n",
        "* Step 2.5: Choose a Model*\n",
        "* Step 3: Prepare Your Data\n",
        "* Step 4: Build, Train, and Evaluate Your Model\n",
        "* Step 5: Tune Hyperparameters\n",
        "* Step 6: Deploy Your Model\n",
        "\n",
        "<img src='https://developers.google.com/machine-learning/guides/text-classification/images/Workflow.png'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UrEkSdhd1SY"
      },
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "import scipy\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md7QWsEsaSPk"
      },
      "source": [
        "## Gather Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM5FwN5CYa2m",
        "outputId": "82d4767e-c8c4-4f59-9774-b94b55fd5712"
      },
      "source": [
        "data_dir = tf.keras.utils.get_file(fname='aclImbd',\n",
        "                                   origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "                                   cache_dir='.',\n",
        "                                   cache_subdir='',\n",
        "                                   untar=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQZE3Pggaif0",
        "outputId": "7409129b-5a7c-4bdd-9d23-df98a292cec0"
      },
      "source": [
        "data_dir = os.path.join(os.path.dirname(data_dir),'aclImdb')\n",
        "print('data directory ',data_dir)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data directory  ./aclImdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIdSA4sDbv-t"
      },
      "source": [
        "## Explore the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyrvkGSsc3eB"
      },
      "source": [
        "### Create Train Test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uID2CssiXhE-"
      },
      "source": [
        "#### Method 1 using `text_dataset_from_directory`\n",
        "\n",
        "`text_dataset_from_directory` utility, which expects a directory structure as follows.\n",
        "\n",
        "<br>\n",
        "main_directory/<br>\n",
        "...class_a/<br>\n",
        "......a_text_1.txt<br>\n",
        "......a_text_2.txt<br>\n",
        "...class_b/<br>\n",
        "......b_text_1.txt<br>\n",
        "......b_text_2.txt<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIx7qOcKd9kD",
        "outputId": "6392748f-8aeb-4264-fe07-7949657b5868"
      },
      "source": [
        "#  '.'\n",
        "print('directory ',os.listdir('.'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "directory  ['.config', 'aclImdb', 'aclImbd.tar.gz', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie74TfBRemdJ",
        "outputId": "873b6678-4027-49e9-9465-5356e49b7052"
      },
      "source": [
        "# './aclImbd'\n",
        "print('directory ',os.listdir(data_dir))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "directory  ['test', 'README', 'imdbEr.txt', 'train', 'imdb.vocab']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwk5F37qgknA",
        "outputId": "a4d4fa8a-75e1-443b-cb87-ec3fa9d08645"
      },
      "source": [
        "# './aclImbd\\train'\n",
        "train_dir = os.path.join(data_dir,'train')\n",
        "# './aclImbd\\test'\n",
        "test_dir = os.path.join(data_dir,'test')\n",
        "print('train directory ',os.listdir(train_dir))\n",
        "print('test directory ',os.listdir(test_dir))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train directory  ['neg', 'urls_pos.txt', 'unsupBow.feat', 'pos', 'urls_unsup.txt', 'urls_neg.txt', 'labeledBow.feat', 'unsup']\n",
            "test directory  ['neg', 'urls_pos.txt', 'pos', 'urls_neg.txt', 'labeledBow.feat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiujAQmJhAVY",
        "outputId": "67e0853c-6633-4b1a-c5ed-683e70109108"
      },
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)\n",
        "print('train directory ',os.listdir(train_dir))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train directory  ['neg', 'urls_pos.txt', 'unsupBow.feat', 'pos', 'urls_unsup.txt', 'urls_neg.txt', 'labeledBow.feat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvkPv0h_bh6L",
        "outputId": "4fb74023-ffcb-43ab-abc1-88a7bfd151fd"
      },
      "source": [
        "# method 1  using 'tf.keras.preprocessing.text_dataset_from_directory'\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(directory=train_dir,seed=42,validation_split=0.2,subset='training')\n",
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(directory=train_dir,seed=42,validation_split=0.2,subset='validation')\n",
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(directory=test_dir,seed=42)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siYE-tk_XuFe"
      },
      "source": [
        "#### Method 2 from scratch using python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3yQUDJQiEeD"
      },
      "source": [
        "# method 2  from scratch using python\n",
        "\n",
        "def train_test_split(data_dir):\n",
        "\n",
        "  train_dir = os.path.join(data_dir,'train')\n",
        "  test_dir = os.path.join(data_dir,'test')\n",
        "\n",
        "  train_data = []\n",
        "  train_labels = []\n",
        "  for review in ['pos', 'neg']:\n",
        "    data_files = os.path.join(train_dir, review)\n",
        "    for fname in sorted(os.listdir(data_files)):\n",
        "      # file directory\n",
        "      f_dir = os.path.join(data_files,fname)\n",
        "      # read the file and append \n",
        "      with open(f_dir) as f:\n",
        "        train_data.append(f.read())\n",
        "      # append the corresponding label\n",
        "      train_labels.append(0 if review == 'neg' else 1)\n",
        "\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  for review in ['pos', 'neg']:\n",
        "    data_files = os.path.join(test_dir, review)\n",
        "    for fname in sorted(os.listdir(data_files)):\n",
        "      # file directory\n",
        "      f_dir = os.path.join(data_files,fname)\n",
        "      # read the file and append \n",
        "      with open(f_dir) as f:\n",
        "        test_data.append(f.read())\n",
        "      # append the corresponding label\n",
        "      test_labels.append(0 if review == 'neg' else 1)\n",
        "\n",
        "  # Shuffle the training data and labels.\n",
        "  seed = 42\n",
        "  random.seed(seed)\n",
        "  random.shuffle(train_data)\n",
        "  random.seed(seed)\n",
        "  random.shuffle(train_labels)\n",
        "\n",
        "  return ((train_data, np.array(train_labels)),(test_data, np.array(test_labels)))\n",
        "\n",
        "\n",
        "\n",
        "# create validtion split from train split\n",
        "def val_split(train_data, train_labels, split_size):\n",
        "  # create validation-set from training-set\n",
        "  split = round(len(train_data)*0.2)\n",
        "  val_data = train_data[:split]\n",
        "  val_labels = train_labels[:split]\n",
        "  train_data = train_data[split:]\n",
        "  train_labels = train_labels[split:]\n",
        "  return ((train_data, train_labels),(val_data, val_labels))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNrB3VKXiqKB",
        "outputId": "c0a4849c-1a29-479d-e822-f66d0f365b11"
      },
      "source": [
        "(train_data, train_labels),(test_data, test_labels) = train_test_split(data_dir)\n",
        "print('Size of training data',len(train_data))\n",
        "print('Size of training labels',len(train_labels))\n",
        "print('Size of testing data',len(test_data))\n",
        "print('Size of testing labels',len(test_labels))\n",
        "\n",
        "print('Create Validation data from training data')\n",
        "(train_data, train_labels),(val_data, val_labels) = val_split(train_data, train_labels, split_size=0.2)\n",
        "print('Size of training data',len(train_data))\n",
        "print('Size of training labels',len(train_labels))\n",
        "print('Size of validation data',len(val_data))\n",
        "print('Size of validation labels',len(val_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data 25000\n",
            "Size of training labels 25000\n",
            "Size of testing data 25000\n",
            "Size of testing labels 25000\n",
            "Create Validation data from training data\n",
            "Size of training data 20000\n",
            "Size of training labels 20000\n",
            "Size of validation data 5000\n",
            "Size of validation labels 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uplVsLLum2_"
      },
      "source": [
        "### Collect Key Metrics\n",
        "Collect the following important metrics that can help characterize your text classification problem:\n",
        "\n",
        "* Number of samples: Total number of examples you have in the data.\n",
        "\n",
        "* Number of classes: Total number of topics or categories in the data.\n",
        "\n",
        "* Number of samples per class: Number of samples per class (topic/category). In a balanced dataset, all classes will have a similar number of samples; in an imbalanced dataset, the number of samples in each class will vary widely.\n",
        "\n",
        "* Number of words per sample: Median number of words in one sample.\n",
        "\n",
        "* Frequency distribution of words: Distribution showing the frequency (number of occurrences) of each word in the dataset.\n",
        "\n",
        "* Distribution of sample length: Distribution showing the number of words per sample in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wByPrPlW00Ah"
      },
      "source": [
        "Total number of examples you have in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIpWlW0ZlfJx",
        "outputId": "8b2b5677-97ae-4d45-a033-cc90cc1f6bd3"
      },
      "source": [
        "number_of_samples = len(train_data)\n",
        "print('Number of samples', number_of_samples)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcmKhMR102fE"
      },
      "source": [
        "Total number of topics or categories in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StIfVPBZvcvZ",
        "outputId": "1c504958-9314-44e4-ff83-76e731e04a62"
      },
      "source": [
        "number_of_classes = len(np.unique(train_labels))\n",
        "print('Number of classes', number_of_classes)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-CCVysX077c"
      },
      "source": [
        "In a balanced dataset, all classes will have a similar number of samples; in an imbalanced dataset, the number of samples in each class will vary widely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r5SxUBIwF5o",
        "outputId": "4945debd-f0a2-4462-da61-17f2470c10df"
      },
      "source": [
        "number_of_samples_per_class = {label:count for label,count in zip(*np.unique(train_labels, return_counts=True))}\n",
        "print('Number of Samples per class', number_of_samples_per_class)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Samples per class {0: 10011, 1: 9989}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWaHPZIG1AkR"
      },
      "source": [
        "Number of words per sample: Median number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVkwQvOpxVPA",
        "outputId": "913eb715-42bd-4114-be3d-8a2e05b008eb"
      },
      "source": [
        "number_of_words_per_sample = [len(sample.split()) for sample in train_data]\n",
        "median_words_per_sample = int(np.median(number_of_words_per_sample))\n",
        "print('Number of words per sample',median_words_per_sample)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words per sample 174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTr1e8WK1LWI"
      },
      "source": [
        "Distribution showing the frequency (number of occurrences) of each word in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NHEAJuyXl7"
      },
      "source": [
        "# Frequency distrubution of words\n",
        "vocab = collections.defaultdict(lambda : 0)\n",
        "for sample in train_data:\n",
        "  for token in sample.split():\n",
        "    vocab[token] += 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkkhDzrtyZKQ"
      },
      "source": [
        "# sort the tokens based on frequency\n",
        "vocab_sorted = sorted(vocab.items(), key=lambda x:x[1], reverse=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vGXjmTwY2NT0",
        "outputId": "4aa6373e-4453-4789-b41b-4b62b767accd"
      },
      "source": [
        "x, height = [key for key, val in vocab_sorted[:10]],[val for key, val in vocab_sorted[:10]]\n",
        "plt.bar(x, height);\n",
        "plt.xlabel('N grams')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Frequency distribution of n-grams');"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nL_egM5CZu_"
      },
      "source": [
        "Distribution of sample length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "T2EFoyCN3KE_",
        "outputId": "2aa4a1b8-5a81-465c-98e4-d4a6b0df3b97"
      },
      "source": [
        "plt.hist([len(sample) for sample in train_data],bins=50);\n",
        "plt.xlabel('Length of a sample')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Sample length distribution');"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vcK2RG-Dc9E"
      },
      "source": [
        "## Choose a model\n",
        "<img src='https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationFlowchart.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x765zzmbGgz8"
      },
      "source": [
        "The ratio of “number of samples” (S) to “number of words per sample” (W) correlates with which model performs well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbemcnRH-LDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186562c9-cf73-40e0-ea6c-dce6e99c1ded"
      },
      "source": [
        "ratio = number_of_samples / median_words_per_sample\n",
        "print('The ratio of “number of samples” (S) to “number of words per sample” (W) is', ratio)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ratio of “number of samples” (S) to “number of words per sample” (W) is 114.94252873563218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oY3E40OIAQv"
      },
      "source": [
        "\n",
        " \n",
        "When the value for this ratio is small (less than 1500) use a sequence model small multi-layer perceptrons that take n-grams as input perform better or at least as well as sequence models. \n",
        " \n",
        "MLPs are simple to define and understand, and they take much less compute time than sequence models.\n",
        "\n",
        "When the value for this ratio is large (>= 1500), use a sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8vsLpK1JB1f"
      },
      "source": [
        "## Prepare your Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RITI9iINOsCx"
      },
      "source": [
        "### N-grams\n",
        "\n",
        "* Tokenize text samples into word `uni+bigrams`,\n",
        "* Vectorize using `tf-idf` encoding,\n",
        "* Select only the top 20,000 features from the vector of tokens by discarding\n",
        " tokens that appear fewer than 2 times and using `f_classif` to calculate feature importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN6-FB-xXFDv"
      },
      "source": [
        "#### Method 1 using Tensorflow `tf.keras.layers.TextVectorization`\n",
        "`tf.keras.layers.experimental.preprocessing.TextVectorization`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkhE4K_KGwT3"
      },
      "source": [
        "# method 1 using 'tf.keras.layers.experimental.preprocessing.TextVectorization'\n",
        "\n",
        "tf_n_grams = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=20000,\n",
        "                                                                          ngrams=(1, 2),\n",
        "                                                                          output_mode='tf_idf',\n",
        "                                                                          pad_to_max_tokens=True)\n",
        "\n",
        "# create a text only dataset and call adapt on it\n",
        "text_ds = raw_train_ds.map(lambda text,label:text)\n",
        "# learn the vocabulary\n",
        "tf_n_grams.adapt(text_ds)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-rmGN2UtWD"
      },
      "source": [
        "# utility that standardize, tokenize and vectorize\n",
        "def tf_vectorize_n_grams(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return tf_n_grams(text), label"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87QfM5xYTRcq"
      },
      "source": [
        "# standardize, tokenize and vectorize the dataset\n",
        "n_grams_train_ds = raw_train_ds.map(tf_vectorize_n_grams)\n",
        "n_grams_val_ds = raw_val_ds.map(tf_vectorize_n_grams)\n",
        "n_grams_test_ds = raw_test_ds.map(tf_vectorize_n_grams)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F-w16xNXWIg"
      },
      "source": [
        "#### Method 2 using Sklearn `sklearn.feature_extraction.text.TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNTpckvMW5qL"
      },
      "source": [
        "def sklearn_vectorize_n_grams(train_data, train_labels, val_data, test_data):\n",
        "  # initialize TfidfVectorizer\n",
        "  tf_idf = TfidfVectorizer(decode_error='replace',\n",
        "                           strip_accents='unicode',\n",
        "                           analyzer='word',\n",
        "                           ngram_range=(1, 2),\n",
        "                           min_df=2,\n",
        "                           )\n",
        "  # Learn vocabulary from training texts and vectorize training texts.                         \n",
        "  train_text = tf_idf.fit_transform(train_data)\n",
        "  # vectorize validation and test texts.\n",
        "  val_text = tf_idf.transform(val_data)\n",
        "  test_text = tf_idf.transform(test_data)\n",
        "\n",
        "\n",
        "  # Select top 'k' of the vectorized features.\n",
        "  top_k = SelectKBest(f_classif, k=min(20000, train_text.shape[1]))\n",
        "  train_text = top_k.fit_transform(train_text, train_labels)\n",
        "  val_text = top_k.transform(val_text)\n",
        "  test_text = top_k.transform(test_text)\n",
        "\n",
        "  return train_text, val_text, test_text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9xzB2lucY8X"
      },
      "source": [
        "# Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "n_grams_train_data, n_grams_val_data, n_grams_test_data = sklearn_vectorize_n_grams(train_data, train_labels, val_data, test_data)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0OwVdExdPuG"
      },
      "source": [
        "With n-gram vector representation, we discard a lot of information about word order and grammar (at best, we can maintain some partial ordering information when n > 1).\n",
        "\n",
        "This is called a bag-of-words approach. This representation is used in conjunction with models that don’t take ordering into account, such as logistic regression, multi-layer perceptrons, gradient boosting machines, support vector machines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71cHFhCTR08W"
      },
      "source": [
        "### Sequence Vector\n",
        "\n",
        "For some text samples, word order is critical to the text’s meaning. For example, the sentences, “I used to hate my commute. My new bike changed that completely” can be understood only when read in order. Models such as CNNs/RNNs can infer meaning from the order of words in a sample. For these models, we represent the text as a sequence of tokens, preserving order.\n",
        "\n",
        "**Tokenization**<br>\n",
        "Text can be represented as either a sequence of characters, or a sequence of words. We have found that using word-level representation provides better performance than character tokens. This is also the general norm that is followed by industry. Using character tokens makes sense only if texts have lots of typos, which isn’t normally the case.\n",
        "\n",
        "**Vectorization**<br>\n",
        "Once we have converted our text samples into sequences of words, we need to turn these sequences into numerical vectors.There are two options available to vectorize the token sequences:\n",
        "* One Hot Encoding<br>\n",
        "Sequences are represented using word vectors in n- dimensional space where n = size of vocabulary. This representation works great when we are tokenizing as characters, and the vocabulary is therefore small. When we are tokenizing as words, the vocabulary will usually have tens of thousands of tokens, making the one-hot vectors very sparse and inefficient.\n",
        "* Word Embedding<br>\n",
        "Words have meaning(s) associated with them. As a result, we can represent word tokens in a dense vector space (~few hundred real numbers), where the location and distance between words indicates how similar they are semantically\n",
        "\n",
        "Sequence models often have such an embedding layer as their first layer. This layer learns to turn word index sequences into word embedding vectors during the training process, such that each word index gets mapped to a dense vector of real values representing that word’s location in semantic space\n",
        "\n",
        "Not all words in our data contribute to label predictions. We can optimize our learning process by discarding rare or irrelevant words from our vocabulary. In fact, we observe that using the most frequent 20,000 features is generally sufficient. This holds true for n-gram models as well \n",
        "\n",
        "steps:<br>\n",
        "* Tokenizes the texts into words\n",
        "* Creates a vocabulary using the top 20,000 tokens\n",
        "* Converts the tokens into sequence vectors\n",
        "* Pads the sequences to a fixed sequence length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjvO2db7VQgg"
      },
      "source": [
        "#### Method 1 using `tf.keras.layers.TextVectorization`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgvqZKmMSdyz"
      },
      "source": [
        "tf_text_vectorize = tf.keras.layers.TextVectorization(max_tokens=20000,\n",
        "                                                               output_mode='int',\n",
        "                                                               output_sequence_length=500)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2o_f_KqSdvz"
      },
      "source": [
        "# create a text only dataset and call adapt\n",
        "text_ds = raw_train_ds.map(lambda text,label:text)\n",
        "\n",
        "# learn the vocab\n",
        "tf_text_vectorize.adapt(text_ds)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTgaTtJ6dF88"
      },
      "source": [
        "# utitliy fn for standardize , tokenize , vectorize\n",
        "def tf_vectorize_text_to_sequence(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return tf_text_vectorize(text), label"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX0YkzXIdb03"
      },
      "source": [
        "# standardize, tokenize and vectorize the dataset\n",
        "sequence_train_ds = raw_train_ds.map(tf_vectorize_text_to_sequence, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "sequence_val_ds = raw_val_ds.map(tf_vectorize_text_to_sequence, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "sequence_test_ds = raw_test_ds.map(tf_vectorize_text_to_sequence, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVu6ZywTaZhA"
      },
      "source": [
        "#### Method 2 using `tf.keras.preprocessing`\n",
        "\n",
        "`text_to_word_sequence(...)`: Converts a text to a sequence of words (or tokens).\n",
        "\n",
        "`pad_sequences(...)`: Pads sequences to the same length.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsFomtTcXtmc"
      },
      "source": [
        "def tf_preprocess_text(train_data, val_data, test_data):\n",
        "  # initialize a tokenizer\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=20000)\n",
        "  # learn the vocab\n",
        "  tokenizer.fit_on_texts(train_data)\n",
        "  # Vectorize training, validation and testing texts.\n",
        "  train_text = tokenizer.texts_to_sequences(train_data)\n",
        "  val_text = tokenizer.texts_to_sequences(val_data)\n",
        "  test_text = tokenizer.texts_to_sequences(test_data)\n",
        "  # get max length\n",
        "  max_len = len(max(train_text, key=len))\n",
        "  if max_len > 500:\n",
        "    max_len = 500\n",
        "  \n",
        "  # Fix sequence length to max value. Sequences shorter than the length are\n",
        "  # padded in the beginning and sequences longer are truncated\n",
        "  # at the beginning.\n",
        "  train_text = tf.keras.preprocessing.sequence.pad_sequences(train_text, maxlen=max_len)\n",
        "  val_text = tf.keras.preprocessing.sequence.pad_sequences(val_text, maxlen=max_len)\n",
        "  test_text = tf.keras.preprocessing.sequence.pad_sequences(test_text, maxlen=max_len)\n",
        "\n",
        "  return train_text, val_text, test_text"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0nisH9MgeKt"
      },
      "source": [
        "# preprocessing text to convert into sequence of word indices\n",
        "sequence_train_data, sequence_val_data, sequence_test_data = tf_preprocess_text(train_data, val_data, test_data)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hezCNgrtiD1l"
      },
      "source": [
        "## Build, Train, and Evaluate Your Model\n",
        "\n",
        "The input layer and the intermediate layers will be constructed differently, depending on whether we’re building an n-gram or a sequence model. But irrespective of model type, the last layer will be the same for a given problem.\n",
        "\n",
        "<img src='https://developers.google.com/machine-learning/guides/text-classification/images/LastLayer.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Zegsrlhc_T"
      },
      "source": [
        "def get_last_layer_units_and_activation(num_class):\n",
        "  if num_class == 2:\n",
        "    units = 1\n",
        "    activation = 'sigmoid'\n",
        "  else:\n",
        "    units = num_class \n",
        "    activation = 'softmax'\n",
        "  \n",
        "  return units, activation"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-0k_hAvkZb_"
      },
      "source": [
        "When the S/W ratio is small, we’ve found that n-gram models perform better than sequence models. Sequence models are better when there are a large number of small, dense vectors. This is because embedding relationships are learned in dense space, and this happens best over many samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG7dOB3IoGXF"
      },
      "source": [
        "### N-gram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry76mDZwhqgi"
      },
      "source": [
        "def mlp(units, activation, layers, dropout_rate, num_class, input_shape):\n",
        "  # last-layer units & activation\n",
        "  op_units, op_activation = get_last_layer_units_and_activation(num_class)\n",
        "  # sequential model\n",
        "  model = tf.keras.Sequential()\n",
        "  # model.add(tf.keras.layers.Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "  for layer in range(layers-1):\n",
        "    model.add(tf.keras.layers.Dense(units=units, activation=activation, input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
        "  # last-layer\n",
        "  model.add(tf.keras.layers.Dense(op_units))\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LWpZycRklwb"
      },
      "source": [
        "# early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11VvVYOji6Qc"
      },
      "source": [
        "#### MLP model using data preprocessed with TF TextVectorization (Method 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxDghNyTi56f"
      },
      "source": [
        "# create an instance of MLP model\n",
        "mlp_model_1 = mlp(units=32,\n",
        "                activation='relu',\n",
        "                layers=2,\n",
        "                dropout_rate=0.5,\n",
        "                num_class=number_of_classes,\n",
        "                input_shape=n_grams_train_data.shape[1:])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe9Ea7T_jaYN",
        "outputId": "8d5d19fd-e868-4e3b-828d-260b515fbac8"
      },
      "source": [
        "mlp_model_1.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                640032    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 640,065\n",
            "Trainable params: 640,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUQK6wecjZ-R"
      },
      "source": [
        "# compile the model\n",
        "mlp_model_1.compile(optimizer='adam',\n",
        "                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNv8fDzRjZ4r",
        "outputId": "28dffacd-2f9b-4a22-cfe5-7c4c19536382"
      },
      "source": [
        "# training\n",
        "mlp_model_1_history = mlp_model_1.fit(n_grams_train_ds,\n",
        "                                      epochs=5,\n",
        "                                      callbacks=[early_stopping],\n",
        "                                      validation_data=n_grams_val_ds )"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 14s 21ms/step - loss: 0.4512 - accuracy: 0.7828 - val_loss: 0.3033 - val_accuracy: 0.8428\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 13s 20ms/step - loss: 0.2395 - accuracy: 0.8907 - val_loss: 0.2537 - val_accuracy: 0.8998\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 13s 20ms/step - loss: 0.1820 - accuracy: 0.9144 - val_loss: 0.2803 - val_accuracy: 0.8952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCCe4zBdmVxY",
        "outputId": "c432b980-bdd8-4842-8877-8393e244f7b9"
      },
      "source": [
        "loss, accuracy = mlp_model_1.evaluate(n_grams_test_ds)\n",
        "print('Loss is ',loss)\n",
        "print('Accuracy is',accuracy)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 10s 12ms/step - loss: 0.2984 - accuracy: 0.8842\n",
            "Loss is  0.29843515157699585\n",
            "Accuracy is 0.8841999769210815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmfMPm_WiojM"
      },
      "source": [
        "#### MLP model using data preprocessed with Sklearn (method 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFosD2sJkHSi"
      },
      "source": [
        "# create an instance of MLP model\n",
        "mlp_model = mlp(units=32,\n",
        "                activation='relu',\n",
        "                layers=2,\n",
        "                dropout_rate=0.5,\n",
        "                num_class=number_of_classes,\n",
        "                input_shape=n_grams_train_data.shape[1:])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFm_tIYVnLbh",
        "outputId": "9faa4341-23cb-46bc-b307-fa3246a371f2"
      },
      "source": [
        "# model summary\n",
        "mlp_model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 32)                640032    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 640,065\n",
            "Trainable params: 640,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkJYHiPCnNCD"
      },
      "source": [
        "# compile the model\n",
        "mlp_model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtX92MUIp0LW"
      },
      "source": [
        "# early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYBKUo4xz2LG"
      },
      "source": [
        "By convention, indices should be sorted in row-major order (or equivalently lexicographic order on the tuples indices[i]). This is not enforced when SparseTensor objects are constructed, but most ops assume correct ordering. If the ordering of sparse tensor st is wrong, a fixed version can be obtained by calling `tf.sparse.reorder(st)`. or `scipy.sparse.csr_matrix.sort_indices`\n",
        "\n",
        "`csr_matrix.sort_indices()`\n",
        "Sort the indices of this matrix in place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5yTcWFztwy"
      },
      "source": [
        "# First you convert the matrix to COO format.\n",
        "#  Then you extract the indices, values, and shape and pass those directly to the SparseTensor constructor.\n",
        "def convert_sparse_matrix_to_tf_sparse(sparse):\n",
        "  coo = sparse.tocoo()\n",
        "  indices = np.mat([coo.row, coo.col]).transpose()\n",
        "  return tf.sparse.reorder(tf.SparseTensor(indices=indices, values=coo.data, dense_shape=coo.shape))\n",
        "\n",
        "n_grams_train_data_tf = convert_sparse_matrix_to_tf_sparse(n_grams_train_data)\n",
        "n_grams_val_data_tf = convert_sparse_matrix_to_tf_sparse(n_grams_val_data)\n",
        "n_grams_test_data_tf = convert_sparse_matrix_to_tf_sparse(n_grams_test_data)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G173d9v8piOI",
        "outputId": "396e18d5-6613-4e10-b096-c28ea1ffcb84"
      },
      "source": [
        "# train the mlp\n",
        "mlp_history = mlp_model.fit(x=n_grams_train_data_tf,\n",
        "              y=train_labels,\n",
        "              batch_size=128,\n",
        "              epochs=5,\n",
        "              callbacks=[early_stopping],\n",
        "              validation_data=(n_grams_val_data_tf, val_labels) \n",
        "              )"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 4s 20ms/step - loss: 0.5750 - accuracy: 0.6138 - val_loss: 0.4451 - val_accuracy: 0.8156\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 0.3483 - accuracy: 0.8694 - val_loss: 0.3127 - val_accuracy: 0.8724\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 0.2466 - accuracy: 0.9117 - val_loss: 0.2652 - val_accuracy: 0.8904\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 0.1948 - accuracy: 0.9316 - val_loss: 0.2434 - val_accuracy: 0.8966\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 0.1624 - accuracy: 0.9448 - val_loss: 0.2329 - val_accuracy: 0.9014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuAiTpbcrRgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5651f33-40f6-45b4-8389-682cd6bef2c2"
      },
      "source": [
        "loss, accuracy = mlp_model.evaluate(n_grams_test_data_tf, test_labels)\n",
        "print('Loss is ',loss)\n",
        "print('Accuracy is',accuracy)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.2400 - accuracy: 0.8940\n",
            "Loss is  0.23997484147548676\n",
            "Accuracy is 0.8939599990844727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNVOgtmXdPxE"
      },
      "source": [
        "### Sequence Model\n",
        "Models that can learn from the adjacency of tokens as sequence models. This includes CNN and RNN classes of models. Data is pre-processed as sequence vectors for these models. \n",
        "\n",
        "sepCNNs, a convolutional network variant that is often more data-efficient and compute-efficient, perform better than the other models.\n",
        "\n",
        "Sequence models generally have a larger number of parameters to learn. The first layer in these models is an embedding layer, which learns the relationship between the words in a dense vector space. Learning word relationships works best over many samples.\n",
        "\n",
        "Words in a given dataset are most likely not unique to that dataset. We can thus learn the relationship between the words in our dataset using other dataset(s). To do so, we can transfer an embedding learned from another dataset into our embedding layer. These embeddings are referred to as pre-trained embeddings. \n",
        "\n",
        "Fine-tuned embeddings yield better accuracy. However, this comes at the expense of increased compute power required to train the network. Given a sufficient number of samples, we could do just as well learning an embedding from scratch. We observed that for S/W > 15K, starting from scratch effectively yields about the same accuracy as using fine-tuned embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZtB8bakr5G5"
      },
      "source": [
        "#### Model using pre-trained embedding\n",
        "Using a pre-trained embedding gives the model a head start in the learning process.\n",
        "\n",
        "* nnlm-en-dim50\n",
        "* Token based text embedding trained on English Google News 7B corpus.\n",
        "\n",
        "* The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
        "* The module preprocesses its input by splitting on spaces.\n",
        "* Note that no matter the length of the input text,\n",
        "* the output shape of the embeddings is: (num_examples, embedding_dimension)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKAPRQqfv9pR"
      },
      "source": [
        "# nnlm-en-dim50\n",
        "# Token based text embedding trained on English Google News 7B corpus.\n",
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "# The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
        "# The module preprocesses its input by splitting on spaces.\n",
        "# Note that no matter the length of the input text,\n",
        "# the output shape of the embeddings is: (num_examples, embedding_dimension)."
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y39p8gUy7RsL"
      },
      "source": [
        "Pre-trained embedding -- we froze the weights of pre-trained embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1rm2GF4qoGT"
      },
      "source": [
        "hub_layer = hub.KerasLayer(handle=embedding, trainable=False, dtype=tf.string)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH2BtqxT-SJk"
      },
      "source": [
        "A simple model that uses pretrained embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29o_wkST2ffO"
      },
      "source": [
        "inputs = tf.keras.Input(shape=[],dtype=tf.string)\n",
        "# embedding layer\n",
        "x = hub_layer(inputs, training=False)\n",
        "# drop out layer\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# dense layer\n",
        "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
        "# drop out layer\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "# classifier\n",
        "outputs = tf.keras.layers.Dense(units=1)(x)\n",
        "# Model using pre-trained embedding\n",
        "pre_trained_embedding_model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j2DLaFK7PIe"
      },
      "source": [
        "# compile the model\n",
        "pre_trained_embedding_model.compile(optimizer='adam',\n",
        "                                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                                    metrics=['accuracy'])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kBc6OA4-tLO",
        "outputId": "15511da8-ef9a-4aeb-c17d-8e67d59cb647"
      },
      "source": [
        "# model summary\n",
        "pre_trained_embedding_model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "keras_layer_1 (KerasLayer)   (None, 50)                48190600  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 48,192,265\n",
            "Trainable params: 1,665\n",
            "Non-trainable params: 48,190,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JBnVO4A-04f",
        "outputId": "ae52b5af-1f96-458a-9f5a-6ff19417413d"
      },
      "source": [
        "# training the model\n",
        "\n",
        "pre_trained_embedding_model.fit(x=train_data,\n",
        "                                y=train_labels.tolist(),\n",
        "                                batch_size=32,\n",
        "                                epochs=10,\n",
        "                                validation_data=(val_data, val_labels.tolist()),\n",
        "                                callbacks=[early_stopping])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 5ms/step - loss: 0.6331 - accuracy: 0.6016 - val_loss: 0.5682 - val_accuracy: 0.6650\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5998 - accuracy: 0.6560 - val_loss: 0.5563 - val_accuracy: 0.6782\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5933 - accuracy: 0.6619 - val_loss: 0.5543 - val_accuracy: 0.6770\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5940 - accuracy: 0.6567 - val_loss: 0.5558 - val_accuracy: 0.7004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55ae0a7150>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDomPn7mrQ77"
      },
      "source": [
        "if we froze the weights of the pre-trained embeddings and trained just the rest of the network, the models did not perform well. \n",
        "\n",
        "This could be because the context in which the embedding layer was trained might have been different from the context in which we were using it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZtG-qeA_osy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755dbd84-0648-4a6b-bcbd-b2b146e7ce5f"
      },
      "source": [
        "loss, accuracy = pre_trained_embedding_model.evaluate(test_data, test_labels.tolist())\n",
        "print('Loss ',loss)\n",
        "print('Accuracy ',accuracy)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.5625 - accuracy: 0.6890\n",
            "Loss  0.5625265836715698\n",
            "Accuracy  0.6890400052070618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKzm4ikrr6w"
      },
      "source": [
        "The data embeddings trained on may not align with the language patterns in our IMDb dataset. The relationships inferred may need some updation  —i.e., the embedding weights may need contextual tuning. We do this in two stages:\n",
        "\n",
        "* In the first run, with the embedding layer weights frozen, we allow the rest of the network to learn.\n",
        "\n",
        "* In the second run, we allow the embedding layer to also learn, making fine adjustments to all weights in the network. We refer to this process as using a fine-tuned embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o93uce7trjHy"
      },
      "source": [
        "# un-froze the weights of embedding layer\n",
        "hub_layer.trainable = True"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7UInjbQscy0"
      },
      "source": [
        "It's important to recompile your model after you make any changes to the `trainable` attribute of any inner layer, so that your changes are take into account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K67wm1esMID"
      },
      "source": [
        "# recompile the model\n",
        "pre_trained_embedding_model.compile(optimizer='adam',\n",
        "                                    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                                    metrics=['accuracy']) "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7jOseUDs386",
        "outputId": "27241ae6-8ba7-4eaf-8e59-cfb8d6c69bd8"
      },
      "source": [
        "# train\n",
        "pre_trained_embedding_model.fit(x=train_data,\n",
        "                                y=train_labels.tolist(),\n",
        "                                batch_size=32,\n",
        "                                epochs=10,\n",
        "                                validation_data=(val_data, val_labels.tolist()),\n",
        "                                callbacks=[early_stopping])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 302s 482ms/step - loss: 0.4066 - accuracy: 0.8033 - val_loss: 0.3060 - val_accuracy: 0.8690\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 319s 511ms/step - loss: 0.2106 - accuracy: 0.9153 - val_loss: 0.3230 - val_accuracy: 0.8726\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55ae07f890>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbSw7DwJtLXH",
        "outputId": "5ee97119-a2c8-4868-932c-df6203215b27"
      },
      "source": [
        "loss, accuracy = pre_trained_embedding_model.evaluate(test_data, test_labels.tolist())\n",
        "print('Loss ',loss)\n",
        "print('Accuracy ',accuracy)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 42s 53ms/step - loss: 0.3376 - accuracy: 0.8697\n",
            "Loss  0.3375718295574188\n",
            "Accuracy  0.8697199821472168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrjqUQYxxdsm"
      },
      "source": [
        "Fine-tuned embeddings yield better accuracy. However, this comes at the expense of increased compute power required to train the network. Given a sufficient number of samples, we could do just as well learning an embedding from scratch. We observed that for S/W > 15K, starting from scratch effectively yields about the same accuracy as using fine-tuned embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rq_eMksxAsz"
      },
      "source": [
        "#### Model learning an embedding from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5raIl1Skwqz0"
      },
      "source": [
        "def sequence_model(in_dim, out_dim, num_blocks, num_filters, kernel_size, pool_size, dropout_rate, num_class):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(input_dim=in_dim, output_dim=out_dim))\n",
        "\n",
        "  for block in range(num_blocks-1):\n",
        "    model.add(tf.keras.layers.SeparableConv1D(filters=num_filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
        "\n",
        "  model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "  model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
        "\n",
        "  op_units, op_activation = get_last_layer_units_and_activation(num_class)\n",
        "  model.add(tf.keras.layers.Dense(units=op_units))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kKvi7kVCdwp"
      },
      "source": [
        "# create an instance of sequence model\n",
        "seq_model = sequence_model(in_dim=20000,\n",
        "                           out_dim=16,\n",
        "                           num_blocks=2,\n",
        "                           num_filters=32,\n",
        "                           kernel_size=3,\n",
        "                           pool_size=3,\n",
        "                           dropout_rate=0.2,\n",
        "                           num_class=2)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYeEcquCTAm"
      },
      "source": [
        "# compile the model\n",
        "seq_model.compile(optimizer='adam',\n",
        "                 loss= tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGI1G_naCSz5",
        "outputId": "33e80b28-e1aa-4483-a5cc-029df770ef07"
      },
      "source": [
        "# Train the model\n",
        "# input to the model -- sequence of word indices  (Sequence vectors created using method 1 or method 2 ) here we are using data preprocessed by method-1\n",
        "seq_model.fit(sequence_train_ds,\n",
        "              epochs=10,\n",
        "              validation_data=sequence_val_ds,\n",
        "              callbacks=[early_stopping])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.6024 - accuracy: 0.5954 - val_loss: 0.3906 - val_accuracy: 0.8188\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3240 - accuracy: 0.8619 - val_loss: 0.2890 - val_accuracy: 0.8784\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.2450 - accuracy: 0.9054 - val_loss: 0.2660 - val_accuracy: 0.8868\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.1954 - accuracy: 0.9250 - val_loss: 0.2578 - val_accuracy: 0.8902\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.1614 - accuracy: 0.9386 - val_loss: 0.2606 - val_accuracy: 0.8914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55b768a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl3ziHBU54w0",
        "outputId": "8e79d89e-ebf6-4106-f2d8-e4f3ce3eb05e"
      },
      "source": [
        "loss, accuracy = seq_model.evaluate(sequence_test_ds)\n",
        "print('Loss ',loss)\n",
        "print('Accuracy ',accuracy)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 10s 12ms/step - loss: 0.2926 - accuracy: 0.8783\n",
            "Loss  0.29260843992233276\n",
            "Accuracy  0.8783199787139893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFKujeJD8uo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}