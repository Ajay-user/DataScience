{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Networks (RNN) with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjx4JSRPRtn7/0FXpooHRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-user/DataScience/blob/master/Notes/Recurrent_Neural_Networks_(RNN)_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWzPFp7GNJoM"
      },
      "source": [
        "https://www.tensorflow.org/guide/keras/rnn#introduction\n",
        "\n",
        "https://machinelearningmastery.com/crash-course-recurrent-neural-networks-deep-learning/\n",
        "\n",
        "https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/\n",
        "\n",
        "# Artificial Neural Networks\n",
        "There are three classes of artificial neural networks , in general. They are:\n",
        "\n",
        "* Multilayer Perceptrons (MLPs)\n",
        "* Convolutional Neural Networks (CNNs)\n",
        "* Recurrent Neural Networks (RNNs)\n",
        "\n",
        "## Multilayer Perceptrons\n",
        "MLPs are suitable for classification prediction problems where inputs are assigned a class or label.\n",
        "\n",
        "They are also suitable for regression prediction problems where a real-valued quantity is predicted given a set of inputs. **Data is often provided in a tabular format, such as you would see in a CSV file or a spreadsheet**.\n",
        "\n",
        "**When to Use MLPs?**\n",
        "\n",
        "Use MLPs For:\n",
        "\n",
        "* Tabular datasets\n",
        "* Classification prediction problems\n",
        "* Regression prediction problems\n",
        "\n",
        "They are very flexible and can be used generally to learn a mapping from inputs to outputs.\n",
        "\n",
        "This flexibility allows them to be applied to other types of data. For example, the pixels of an image can be reduced down to one long row of data and fed into a MLP. The words of a document can also be reduced to one long row of data and fed to a MLP. Even the lag observations for a time series prediction problem can be reduced to a long row of data and fed to a MLP.\n",
        "\n",
        "As such, if your data is in a form other than a tabular dataset, such as an image, document, or time series, it's recommend at least testing an MLP on your problem. The results can be used as a baseline point of comparison to confirm that other models that may appear better suited add value.\n",
        "\n",
        "## Convolutional Neural Networks\n",
        "**When to Use Convolutional Neural Networks?**\n",
        "\n",
        "Convolutional Neural Networks, or CNNs, were designed to map image data to an output variable.\n",
        "\n",
        "They have proven so effective that they are the go-to method for any type of prediction problem involving image data as an input.\n",
        "\n",
        "\n",
        "The benefit of using CNNs is their ability to develop an internal representation of a two-dimensional image. This allows the model to learn position and scale in variant structures in the data, which is important when working with images.\n",
        "\n",
        "**Use CNNs For:**\n",
        "\n",
        "* Image data\n",
        "* lassification prediction problems\n",
        "* Regression prediction problems\n",
        "\n",
        "**More generally, CNNs work well with data that has a spatial relationship**.\n",
        "\n",
        "The CNN input is traditionally two-dimensional, a field or matrix, but can also be changed to be one-dimensional, allowing it to develop an internal representation of a one-dimensional sequence.\n",
        "\n",
        "This allows the CNN to be used more generally on other types of data that has a spatial relationship. For example, there is an order relationship between words in a document of text. There is an ordered relationship in the time steps of a time series.\n",
        "\n",
        "Although not specifically developed for non-image data, CNNs achieve state-of-the-art results on problems such as document classification used in sentiment analysis and related problems.\n",
        "\n",
        "Try CNNs On:\n",
        "\n",
        "Text data\n",
        "Time series data\n",
        "Sequence input data\n",
        "\n",
        "##  Recurrent Neural Networks\n",
        "**When to Use Recurrent Neural Networks?** \n",
        "\n",
        "Recurrent Neural Networks, or RNNs, were designed to work with sequence prediction problems.\n",
        "\n",
        "Sequence prediction problems come in many forms and are best described by the types of inputs and outputs supported.\n",
        "\n",
        "Some examples of sequence prediction problems include:\n",
        "\n",
        "**One-to-Many**: An observation as input mapped to a sequence with multiple steps as an output.\n",
        "\n",
        "**Many-to-One**: A sequence of multiple steps as input mapped to class or quantity prediction.\n",
        "\n",
        "**Many-to-Many**: A sequence of multiple steps as input mapped to a sequence with multiple steps as output.\n",
        "\n",
        "**The Many-to-Many problem is often referred to as sequence-to-sequence, or seq2seq for short**.\n",
        "\n",
        "\n",
        "Recurrent neural networks were traditionally difficult to train.\n",
        "\n",
        "The Long Short-Term Memory, or LSTM, network is perhaps the most successful RNN because it overcomes the problems of training a recurrent network and in turn has been used on a wide range of applications.\n",
        "\n",
        "**RNNs in general and LSTMs in particular have received the most success when working with sequences of words and paragraphs, generally called natural language processing.**\n",
        "\n",
        "This includes both sequences of text and sequences of spoken language represented as a time series. They are also used as generative models that require a sequence output, not only with text, but on applications such as generating handwriting.\n",
        "\n",
        "**Use RNNs For:**\n",
        "\n",
        "* Text data\n",
        "* Speech data\n",
        "* Classification prediction problems\n",
        "* Regression prediction problems\n",
        "* Generative models\n",
        "\n",
        "**Recurrent neural networks are not appropriate for tabular datasets as you would see in a CSV file or spreadsheet. They are also not appropriate for image data input.**\n",
        "\n",
        "Don’t Use RNNs For:\n",
        "\n",
        "* Tabular data\n",
        "* Image data\n",
        "\n",
        "RNNs and LSTMs have been tested on time series forecasting problems, but the results have been poor, to say the least. Autoregression methods, even linear methods often perform much better. LSTMs are often outperformed by simple MLPs applied on the same data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language**.\n",
        "\n",
        "Schematically, a RNN layer uses a for loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has seen so far.\n",
        "\n",
        "The Keras RNN API is designed with a focus on:\n",
        "\n",
        "* Ease of use: the built-in `keras.layers.RNN`, `keras.layers.LSTM`, `keras.layers.GRU` layers enable you to quickly build recurrent models without having to make difficult configuration choices.\n",
        "\n",
        "* Ease of customization: You can also define your own RNN cell layer (the inner part of the for loop) with custom behavior, and use it with the generic `keras.layers.RNN layer` (the for loop itself). This allows you to quickly prototype different research ideas in a flexible way with minimal code.\n",
        "\n",
        "\n",
        "\n",
        "Recurrent neural networks have connections that have loops, adding feedback and memory to the networks over time. This memory allows this type of network to learn and generalize across sequences of inputs rather than individual patterns.\n",
        "\n",
        "A powerful type of Recurrent Neural Network called the Long Short-Term Memory Network has been shown to be particularly effective when stacked into a deep configuration, achieving state-of-the-art results on a diverse array of problems from language translation to automatic captioning of images and videos.\n",
        "\n",
        "**Support For Sequences in Neural Networks**\n",
        "\n",
        "There are some problem types that are best framed involving either a sequence as an input or an output.\n",
        "\n",
        "For example, consider a univariate time series problem, like the price of a stock over time. This dataset can be framed as a prediction problem for a classical feedforward multilayer Perceptron network by defining a windows size (e.g. 5) and training the network to learn to make short term predictions from the fixed sized window of inputs.\n",
        "\n",
        "This would work, but is very limited. The window of inputs adds memory to the problem, but is limited to just a fixed number of points and must be chosen with sufficient knowledge of the problem. A naive window would not capture the broader trends over minutes, hours and days that might be relevant to making a prediction. From one prediction to the next, the network only knows about the specific inputs it is provided.\n",
        "\n",
        "Univariate time series prediction is important, but there are even more interesting problems that involve sequences.\n",
        "\n",
        "Consider the following taxonomy of sequence problems: \n",
        "\n",
        "* One-to-Many: sequence output, for image captioning.\n",
        "* Many-to-One: sequence input, for sentiment classification.\n",
        "* Many-to-Many: sequence in and out, for machine translation.\n",
        "* Synched Many-to-Many: synced sequences in and out, for video classification.\n",
        "\n",
        "We can also see that a one-to-one example of input to output would be an example of a classical feedforward neural network for a prediction task like image classification.\n",
        "\n",
        "Support for sequences in neural networks is an important class of problem and one where deep learning has recently shown impressive results State-of-the art results have been using a type of network specifically designed for sequence problems called recurrent neural networks.\n",
        "\n",
        "**Recurrent Neural Networks**\n",
        "\n",
        "Recurrent Neural Networks or RNNs are a special type of neural network designed for sequence problems.\n",
        "\n",
        "Given a standard feed-forward multilayer Perceptron network, a recurrent neural network can be thought of as the addition of loops to the architecture. For example, in a given layer, each neuron may pass its signal latterly (sideways) in addition to forward to the next layer. The output of the network may feedback as an input to the network with the next input vector. And so on.\n",
        "\n",
        "**The recurrent connections add state or memory to the network and allow it to learn broader abstractions from the input sequences**.\n",
        "\n",
        "The field of recurrent neural networks is well established with popular methods. For the techniques to be effective on real problems, two major issues needed to be resolved for the network to be useful.\n",
        "\n",
        "* How to train the network with Backpropagation.\n",
        "* How to stop gradients vanishing or exploding during training.\n",
        "\n",
        "\n",
        "**How to Train Recurrent Neural Networks**\n",
        "\n",
        "The staple technique for training feedforward neural networks is to back propagate error and update the network weights.\n",
        "\n",
        "Backpropagation breaks down in a recurrent neural network, because of the recurrent or loop connections.\n",
        "\n",
        "This was addressed with a modification of the Backpropagation technique called **Backpropagation Through Time or BPTT**.\n",
        "\n",
        "Instead of performing backpropagation on the recurrent network as stated, the structure of the network is unrolled, where copies of the neurons that have recurrent connections are created. For example a single neuron with a connection to itself (A->A) could be represented as two neurons with the same weight values (A->B).\n",
        "\n",
        "This allows the cyclic graph of a recurrent neural network to be turned into an acyclic graph like a classic feed-forward neural network, and Backpropagation can be applied.\n",
        "\n",
        "**How to Have Stable Gradients During Training**\n",
        "\n",
        "When Backpropagation is used in very deep neural networks and in unrolled recurrent neural networks, the gradients that are calculated in order to update the weights can become unstable.\n",
        "\n",
        "They can become very large numbers called exploding gradients or very small numbers called the vanishing gradient problem. These large numbers in turn are used to update the weights in the network, making training unstable and the network unreliable.\n",
        "\n",
        "This problem is alleviated in deep multilayer Perceptron networks through the use of the Rectifier transfer function, and even more exotic but now less popular approaches of using unsupervised pre-training of layers.\n",
        "\n",
        "In recurrent neural network architectures, this problem has been alleviated using a new type of architecture called the Long Short-Term Memory Networks that allows deep recurrent networks to be trained.\n",
        "\n",
        "## Long Short-Term Memory Networks\n",
        "\n",
        "The Long Short-Term Memory or LSTM network is a recurrent neural network that is trained using Backpropagation Through Time and overcomes the vanishing gradient problem.\n",
        "\n",
        "As such it can be used to create large (stacked) recurrent networks, that in turn can be used to address difficult sequence problems in machine learning and achieve state-of-the-art results.\n",
        "\n",
        "**Instead of neurons, LSTM networks have memory blocks that are connected into layers**.\n",
        "\n",
        "A block has components that make it smarter than a classical neuron and a memory for recent sequences. \n",
        "\n",
        "A block contains gates that manage the block’s state and output. A unit operates upon an input sequence and each gate within a unit uses the sigmoid activation function to control whether they are triggered or not, making the change of state and addition of information flowing through the unit conditional.\n",
        "\n",
        "There are three types of gates within a memory unit:\n",
        "\n",
        "* Forget Gate: conditionally decides what information to discard from the unit.\n",
        "* Input Gate: conditionally decides which values from the input to update the memory state.\n",
        "* Output Gate: conditionally decides what to output based on input and the memory of the unit.\n",
        "\n",
        "Each unit is like a mini state machine where the gates of the units have weights that are learned during the training procedure.\n",
        "\n",
        "You can see how you may achieve a sophisticated learning and memory from a layer of LSTMs, and it is not hard to imagine how higher-order abstractions may be layered with multiple such layers.\n",
        "\n",
        "\n",
        "\n",
        "**Long Short-Term Memory, or LSTM, recurrent neural networks expect three-dimensional input in the Keras Python deep learning library**.\n",
        "\n",
        "If you have a long sequence of thousands of observations in your time series data, you must split your time series into samples and then reshape it for your LSTM model.\n",
        "\n",
        "\n",
        "* LSTMs expect 3D input\n",
        "* LSTMs don’t like sequences of more than 200-400 time steps, so the data will need to be split into samples.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfucoRYiNGn4"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-xbZz2S6E9"
      },
      "source": [
        "## Built-in RNN layers\n",
        "\n",
        "Built-in RNN layers: a simple example\n",
        "\n",
        "There are three built-in RNN layers in Keras:\n",
        "\n",
        "`keras.layers.SimpleRNN`, a fully-connected RNN where the output from previous timestep is to be fed to next timestep.\n",
        "\n",
        "`keras.layers.GRU`, first proposed in Cho et al., 2014.\n",
        "\n",
        "`keras.layers.LSTM`, first proposed in Hochreiter & Schmidhuber, 1997."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnAVRTplSu2m",
        "outputId": "318110cd-94b7-40cb-98c8-72b48baa8ef9"
      },
      "source": [
        "# Here is a simple example of a Sequential model that processes sequences of integers,\n",
        "# embeds each integer into a 64-dimensional vector,\n",
        "# then processes the sequence of vectors using a LSTM layer.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                            # Add an Embedding layer expecting input vocab of size 1000, and\n",
        "                            # output embedding dimension of size 64.\n",
        "                             tf.keras.layers.Embedding(input_dim=1000, output_dim=64),\n",
        "                            #  add a lstm layer with 128 units \n",
        "                             tf.keras.layers.LSTM(128),\n",
        "                            #  add a dense layer with 10 units\n",
        "                             tf.keras.layers.Dense(10)\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 164,106\n",
            "Trainable params: 164,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zeQ70zpWCA-"
      },
      "source": [
        "Built-in RNNs support a number of useful features:\n",
        "\n",
        "* Recurrent dropout, via the `dropout` and `recurrent_dropout` arguments\n",
        "* Ability to process an input sequence in reverse, via the `go_backwards `argument\n",
        "* Loop unrolling (which can lead to a large speedup when processing short sequences on CPU), via the `unroll` argument\n",
        "\n",
        "\n",
        "## Outputs and states\n",
        "\n",
        "By default, the output of a RNN layer contains a single vector per sample. This vector is the RNN cell output corresponding to the last timestep, containing information about the entire input sequence. The shape of this output is (batch_size, units) where units corresponds to the units argument passed to the layer's constructor.\n",
        "\n",
        "A RNN layer can also return the entire sequence of outputs for each sample (one vector per timestep per sample), if you set `return_sequences=True`. The shape of this output is (batch_size, timesteps, units)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sB3xE2iTQTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5b88a5-21a9-44ec-e5e7-a5898834a2e2"
      },
      "source": [
        "from tensorflow.python.keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential([\n",
        "                            tf.keras.layers.Embedding(1000, 64),\n",
        "                            #  the output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "                            tf.keras.layers.GRU(256 , return_sequences=True),\n",
        "                            # the output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "                            tf.keras.layers.SimpleRNN(128),\n",
        "                            tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, None, 256)         247296    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 361,866\n",
            "Trainable params: 361,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-zKbT2xY15M"
      },
      "source": [
        "In addition, a RNN layer can return its final internal state(s). The returned states can be used to resume the RNN execution later, or to initialize another RNN. This setting is commonly used in the encoder-decoder sequence-to-sequence model, where the encoder final state is used as the initial state of the decoder.\n",
        "\n",
        "To configure a RNN layer to return its internal state, set the return_state parameter to True when creating the layer. Note that LSTM has 2 state tensors, but GRU only has one.\n",
        "\n",
        "**To configure the initial state of the layer, just call the layer with additional `keyword argument initial_state`.**\n",
        "\n",
        " **Note that the shape of the state needs to match the unit size of the layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS57LGEVYZDb",
        "outputId": "d64b704e-a025-45b7-b0dc-f0d7b8bf0da9"
      },
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = tf.keras.layers.Input(shape=(None,))\n",
        "encoder_embedded = tf.keras.layers.Embedding(encoder_vocab, 64)(encoder_input)\n",
        "# Return states in addition to output\n",
        "encoder_output, encoder_state_h, encoder_state_c = tf.keras.layers.LSTM(64, return_state=True, name='encoder')(encoder_embedded)\n",
        "\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_embedded = tf.keras.layers.Embedding(decoder_vocab, 64)(decoder_input)\n",
        "\n",
        "# Pass the 2 states to a new LSTM layer, as initial state\n",
        "decoder_output = tf.keras.layers.LSTM(64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
        "\n",
        "output = tf.keras.layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, None, 64)     64000       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 64)     128000      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder (LSTM)                  (None, 64)           33024       embedding_5[0][0]                \n",
            "                                                                 encoder[0][1]                    \n",
            "                                                                 encoder[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 258,698\n",
            "Trainable params: 258,698\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-2wH4jWe1lk"
      },
      "source": [
        "## RNN layers and RNN cells\n",
        "In addition to the built-in RNN layers, the RNN API also provides cell-level APIs. Unlike RNN layers, which processes whole batches of input sequences, the RNN cell only processes a single timestep.\n",
        "\n",
        "The cell is the inside of the for loop of a RNN layer. Wrapping a cell inside a `keras.layers.RNN layer` gives you a layer capable of processing batches of sequences, e.g. `RNN(LSTMCell(10))`.\n",
        "\n",
        "Mathematically, `RNN(LSTMCell(10))` produces the same result as LSTM(10).  Using the built-in GRU and LSTM layers enable the use of CuDNN and you may see better performance.\n",
        "\n",
        "There are three built-in RNN cells, each of them corresponding to the matching RNN layer.\n",
        "\n",
        "* keras.layers.SimpleRNNCell corresponds to the SimpleRNN layer.\n",
        "\n",
        "* keras.layers.GRUCell corresponds to the GRU layer.\n",
        "\n",
        "* keras.layers.LSTMCell corresponds to the LSTM layer.\n",
        "\n",
        "The cell abstraction, together with the generic `keras.layers.RNN` class, make it very easy to implement custom RNN architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELni7N4frvFg"
      },
      "source": [
        "## Cross-batch statefulness\n",
        "When processing very long sequences (possibly infinite), you may want to use the pattern of cross-batch statefulness.\n",
        "\n",
        "Normally, the internal state of a RNN layer is reset every time it sees a new batch (i.e. every sample seen by the layer is assumed to be independent of the past). The layer will only maintain a state while processing a given sample.\n",
        "\n",
        "If you have very long sequences though, it is useful to break them into shorter sequences, and to feed these shorter sequences sequentially into a RNN layer without resetting the layer's state. That way, the layer can retain information about the entirety of the sequence, even though it's only seeing one sub-sequence at a time.\n",
        "\n",
        "You can do this by setting `stateful=True` in the constructor.\n",
        "\n",
        "If you have a sequence s = [t0, t1, ... t1546, t1547], you would split it into e.g.\n",
        "\n",
        "<br>\n",
        "s1 = [t0, t1, ... t100]<br>\n",
        "s2 = [t101, ... t201]<br>\n",
        "...<br>\n",
        "s16 = [t1501, ... t1547]<br>\n",
        "<br>\n",
        "\n",
        "Then you would process it via:\n",
        "\n",
        "<br>\n",
        "lstm_layer = layers.LSTM(64, stateful=True)<br>\n",
        "for s in sub_sequences:<br>\n",
        "  output = lstm_layer(s)<br>\n",
        "<br>\n",
        "\n",
        "When you want to clear the state, you can use layer.reset_states().\n",
        "\n",
        "Note: In this setup, sample i in a given batch is assumed to be the continuation of sample i in the previous batch. This means that all batches should contain the same number of samples (batch size). E.g. if a batch contains `[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]`, the next batch should contain `[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rer7_mJhcQmo"
      },
      "source": [
        "para1 = np.random.random((20,10,30)).astype(np.float32)\n",
        "para2 = np.random.random((20,10,30)).astype(np.float32)\n",
        "para3 = np.random.random((20,10,30)).astype(np.float32)\n",
        "\n",
        "lstm_layer = tf.keras.layers.LSTM(64, stateful=True)\n",
        "\n",
        "output = lstm_layer(para1)\n",
        "output = lstm_layer(para2)\n",
        "output = lstm_layer(para3)\n",
        "\n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "\n",
        "lstm_layer.reset_states()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXk4zacIv_uo"
      },
      "source": [
        "## RNN State Reuse\n",
        "\n",
        "The recorded states of the RNN layer are not included in the `layer.weights()`. If you would like to reuse the state from a RNN layer, you can retrieve the states value by `layer.states` and use it as the initial state for a new layer via the Keras functional API like `new_layer(inputs, initial_state=layer.states)`, or model subclassing.\n",
        "\n",
        "Note that sequential model might not be used in this case since it only supports layers with single input and output, the extra input of initial state makes it impossible to use here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qzduNqkstFH"
      },
      "source": [
        "para1 = np.random.random((20,10,30)).astype(np.float32)\n",
        "para2 = np.random.random((20,10,30)).astype(np.float32)\n",
        "para3 = np.random.random((20,10,30)).astype(np.float32)\n",
        "\n",
        "lstm_layer = tf.keras.layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(para1)\n",
        "output = lstm_layer(para2)\n",
        "\n",
        "existing_state = lstm_layer.states\n",
        "\n",
        "new_lstm_layer = tf.keras.layers.LSTM(64)(para3, initial_state=existing_state)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCnpixTm5Dk_"
      },
      "source": [
        "## Bidirectional RNNs\n",
        "**For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards**.\n",
        "\n",
        "For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
        "\n",
        "Keras provides an easy API for you to build such bidirectional RNNs: the `keras.layers.Bidirectional` wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O22XhChoxMQ1",
        "outputId": "48babbd8-43ef-46a8-fb51-c67c0348cdd4"
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(1000, 64),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True),input_shape=(5, 10)),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "                             tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 64)          24832     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 114,314\n",
            "Trainable params: 114,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEb4Pn4C_QrE"
      },
      "source": [
        "Under the hood, Bidirectional will copy the RNN layer passed in, and flip the go_backwards field of the newly copied layer, so that it will process the inputs in reverse order.\n",
        "\n",
        "The output of the Bidirectional RNN will be, by default, the concatenation of the forward layer output and the backward layer output. If you need a different merging behavior, e.g. concatenation, change the merge_mode parameter in the Bidirectional wrapper constructor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIsQmikU_eao"
      },
      "source": [
        "## Performance optimization and CuDNN kernels\n",
        "**In TensorFlow 2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default when a GPU is available**. With this change, the prior keras.layers.CuDNNLSTM/CuDNNGRU layers have been deprecated, and you can build your model without worrying about the hardware it will run on.\n",
        "\n",
        "Since the CuDNN kernel is built with certain assumptions, this means the layer will not be able to use the CuDNN kernel if you change the defaults of the built-in LSTM or GRU layers. E.g.:\n",
        "\n",
        "* Changing the activation function from `tanh` to something else.\n",
        "* Changing the recurrent_activation function from `sigmoid` to something else.\n",
        "* Using recurrent_dropout > 0.\n",
        "* Setting `unroll` to `True`, which forces LSTM/GRU to decompose the inner tf.while_loop into an unrolled for loop.\n",
        "* Setting `use_bias` to False.\n",
        "* Using masking when the input data is not strictly right padded (if the mask corresponds to strictly right padded data, CuDNN can still be used. This is the most common case)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoodUu3eG1vf"
      },
      "source": [
        "## Using CuDNN kernels when available\n",
        "Let's build a simple LSTM model to demonstrate the performance difference.\n",
        "\n",
        "We'll use as input sequences the sequence of rows of MNIST digits (treating each row of pixels as a timestep), and we'll predict the digit's label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoBMMN1B--M7"
      },
      "source": [
        "\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "\n",
        "batch_size = 64\n",
        "input_dim = 28\n",
        "units = 64\n",
        "# labels are from 0 to 9\n",
        "output_dim = 10\n",
        "\n",
        "def build_model(allow_cudnn_kernel=False):\n",
        "\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "\n",
        "    if allow_cudnn_kernel:\n",
        "      lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None,input_dim))\n",
        "    else:\n",
        "      lstm_layer = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(units), input_shape=(None, input_dim))\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "                                 lstm_layer,\n",
        "                                 tf.keras.layers.BatchNormalization(),\n",
        "                                 tf.keras.layers.Dense(output_dim)\n",
        "    ])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K4iCNL-LVFq",
        "outputId": "c25b7e57-13b8-4916-e58d-cceb8098d79b"
      },
      "source": [
        "# data loading\n",
        "(X_train, y_train),(X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print('Shape of training data',X_train.shape)\n",
        "print('Shape of training labels',y_train.shape)\n",
        "print('Shape of testing data',X_test.shape)\n",
        "print('Shape of testing labels',y_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data (60000, 28, 28)\n",
            "Shape of training labels (60000,)\n",
            "Shape of testing data (10000, 28, 28)\n",
            "Shape of testing labels (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_JsIEOwKNM4",
        "outputId": "8b053f45-3ac8-47b6-a9bb-97b820ce5978"
      },
      "source": [
        "cudnn_model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "cudnn_model.compile(optimizer='sgd',\n",
        "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "cudnn_model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test), batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 22s 21ms/step - loss: 1.0804 - accuracy: 0.6384 - val_loss: 0.7351 - val_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29a9cd2750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkc-BLVlM5v9"
      },
      "source": [
        "Now, let's compare to a model that does not use the CuDNN kernel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxmmTm6tMrZl",
        "outputId": "57a10cb3-e36d-4472-bae1-a35c88ac078e"
      },
      "source": [
        "non_cudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "\n",
        "non_cudnn_model.set_weights(cudnn_model.get_weights())\n",
        "\n",
        "non_cudnn_model.compile(optimizer='sgd',\n",
        "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                        metrics=['accuracy'])\n",
        "non_cudnn_model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test), batch_size=batch_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 20s 21ms/step - loss: 0.6629 - accuracy: 0.7808 - val_loss: 0.5878 - val_accuracy: 0.8022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29aa083090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AJo8WzeOLe8"
      },
      "source": [
        "When running on a machine with a NVIDIA GPU and CuDNN installed, the model built with CuDNN is much faster to train compared to the model that uses the regular TensorFlow kernel.\n",
        "\n",
        "The same CuDNN-enabled model can also be used to run inference in a CPU-only environment. The tf.device annotation below is just forcing the device placement. The model will run on CPU by default if no GPU is available.\n",
        "\n",
        "You simply don't have to worry about the hardware you're running on anymore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjmopeXhNeK9"
      },
      "source": [
        "with tf.device('CPU:0'):\n",
        "  model = build_model(allow_cudnn_kernel=True)\n",
        "  model.set_weights(cudnn_model.get_weights())\n",
        "  preds = model.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "FxmZDvPmPAww",
        "outputId": "5ee2872f-40fb-4dfb-ebf9-e5f7bb05ce9e"
      },
      "source": [
        "sample_0 = np.argmax(preds[0])\n",
        "plt.imshow(X_test[0])\n",
        "plt.title('Actual :'+str(y_test[0])+', predicted :'+str(sample_0));"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfdXab0VPC8H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}