This project demonstrates how to create and train a sequence-to-sequence Transformer model to translate Malayalam into English. 

Transformers are deep neural networks that replace CNNs and RNNs with self-attention. Self attention allows Transformers to easily transmit information across the input sequences.

Neural networks for machine translation typically contain an encoder reading the input sentence and generating a representation of it. A decoder then generates the output sentence word by word while consulting the representation generated by the encoder. The Transformer starts by generating initial representations, or embeddings, for each word... Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations.


## Deep learning models are data hungry

* Data is collected from various sources and has lot of errors

* The project is for demonstration purpose only so less focus on data quality and more on model architecture

* We only have short sentences in our dataset. 

* Since majority of sentences are short, the sequence length is capped at 16

* Quality of model depends on the quality of the data

### Here are some translations made by the model

----------------------------------------------------------------------
English :
the carton is gold <br>
Prediction :
കാർട്ടൂൺ സ്വർണ്ണമാണ്<br>
True labels used to train the model :
സ്വർണ നിറമുള്ള കാർഡ്ബോർഡ് പെട്ടി<br>
----------------------------------------------------------------------
English :
large tan clay pot <br>
Prediction :
വലിയ ടാൻ കളിമൺ കലം <br>
True labels used to train the model :
വലിയ ടാൻ കളിമൺ കലം <br>
----------------------------------------------------------------------
English :
the signs are neon <br>
Prediction :
അടയാളങ്ങൾ നിയോൺ ആണ് <br>
True labels used to train the model :
അടയാളങ്ങൾ നിയോൺ ആണ് <br>
----------------------------------------------------------------------
English :
man wearing a striped sweater  <br>
Prediction :
വരയുള്ള സ്വെറ്റർ ധരിച്ച മനുഷ്യൻ  <br>
True labels used to train the model :
വരയുള്ള സ്വെറ്റർ ധരിച്ച മനുഷ്യൻ  <br>
----------------------------------------------------------------------
English :
White Dole sticker on a banana. <br>
Prediction :
ഒരു വാഴപ്പഴത്തിൽ വെള്ള നിറത്തിലുള്ള സ്റ്റിക്കർ <br>
True labels used to train the model :
ഒരു വാഴപ്പഴത്തിൽ വെള്ള നിറത്തിലുള്ള ഡോൾ സ്റ്റിക്കർ. <br>
----------------------------------------------------------------------
English :
clock in front of tall building <br>
Prediction :
ഉയരമുള്ള കെട്ടിടത്തിന്റെ മുൻവശത്തെ ഘടികാരം <br>
True labels used to train the model :
ഉയരമുള്ള കെട്ടിടത്തിന് മുന്നിൽ ക്ലോക്ക് <br>
----------------------------------------------------------------------
English :
round gourmet style pizza cut in 6 slices <br>
Prediction :
റൗണ്ട് ണ്ട് സ്റ്റൈൽ പിസ്സ 6 കഷണങ്ങളായി മുറിച്ചു <br>
True labels used to train the model :
റ s ണ്ട് ഗ our ർമെറ്റ് സ്റ്റൈൽ പിസ്സ 6 കഷണങ്ങളായി മുറിച്ചു <br>
----------------------------------------------------------------------
English :
Gourmet pizza with several toppings <br>
Prediction :
നിരവധി ടോപ്പിംഗുകളുള്ള പിസ്സ <br>
True labels used to train the model :
നിരവധി ടോപ്പിംഗുകളുള്ള ഗൗർമെറ്റ് പിസ്സ <br>
----------------------------------------------------------------------
English :
sandwiches on the plate <br>
Prediction :
പ്ലേറ്റിൽ സാൻഡ്വിച്ചുകൾ <br>
True labels used to train the model :
പാത്രത്തിൽ സാൻഡ്‌വിച്ചുകൾ <br>
----------------------------------------------------------------------
English :
red caution light between trains <br>
Prediction :
ചുവന്ന ജാഗ്രത വെളിച്ചം <br>
True labels used to train the model :
ട്രെയിനുകൾക്കിടയിൽ ചുവന്ന ജാഗ്രത വെളിച്ചം <br>
----------------------------------------------------------------------
English :
reflection of lights on water's surface <br>
Prediction :
ജലത്തിന്റെ ലൈറ്റുകളുടെ പ്രതിഫലനം <br>
True labels used to train the model :
ജലത്തിന്റെ ഉപരിതലത്തിലെ ലൈറ്റുകളുടെ പ്രതിഫലനം  <br>
----------------------------------------------------------------------

# Our data has lot of errors but model learned to generalize
The data was collected from various sources and is not perfect. Some translation are wrong but after sufficent training model learned to generalize.  <br>
We can see many examples where training data has a bad translation but the model was able to provide correct translation after training. <br>

English :
this is a cow <br>
Prediction :
ഇതൊരു പശുവാണ് <br>
True labels used to train the model :
ചാരനിറത്തിലുള്ള റോഡിന്റെ വശങ്ങളിൽ പച്ച പുല്ലിന്റെ സ്ട്രിപ്പുകൾ <br>
----------------------------------------------------------------------
English :
a dog on a couch <br>
Prediction :
കട്ടിലിൽ ഒരു നായ <br>
True labels used to train the model :
ഒരു ബാഗ് കോട്ടൺ മിഠായി <br>
----------------------------------------------------------------------
English :
this is a blender <br>
Prediction :
ഇതൊരു ബ്ലെൻഡർ <br>
True labels used to train the model :
ചാരനിറത്തിലുള്ള റോഡിന്റെ വശങ്ങളിൽ പച്ച പുല്ലിന്റെ സ്ട്രിപ്പുകൾ <br>
----------------------------------------------------------------------
